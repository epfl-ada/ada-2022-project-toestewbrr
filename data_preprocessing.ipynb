{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "AYC13i4R39dN"
   },
   "source": [
    "# Applied Data Analysis Project\n",
    "**Team**: ToeStewBrr - Alexander Sternfeld, Marguerite Thery, Antoine Bonnet, Hugo Bordereaux\n",
    "\n",
    "**Dataset**: CMU Movie Summary Corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MlSSpJAG39dP"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import urllib\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import re\n",
    "import gzip\n",
    "import ast\n",
    "from nltk.tree import Tree\n",
    "import xml.etree.ElementTree as ET\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TadIrDF39dR"
   },
   "source": [
    "## 1. Loading data\n",
    "\n",
    "We first extract all files from the [MoviesSummaries dataset](http://www.cs.cmu.edu/~ark/personas/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Data/MovieSummaries'):\n",
    "    filename = 'http://www.cs.cmu.edu/~ark/personas/data/MovieSummaries.tar.gz'\n",
    "    my_tar = tarfile.open(fileobj=urllib.request.urlopen(filename), mode=\"r:gz\") \n",
    "    my_tar.extractall('./Data') # specify which folder to extract to\n",
    "    my_tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`corenlp_plot_summaries.tar.gz [628 M, separate download]`: The plot summary of each movie, run through the Stanford CoreNLP pipeline (tagging, parsing, NER and coref). Each filename begins with the Wikipedia movie ID (which indexes into movie.metadata.tsv).\n",
    "\n",
    "We now extract all coreNLP files, then uncompress them to the XML format. \n",
    "\n",
    "Note: Extraction of CoreNLP files takes 15 minutes, while conversion takes 30 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all coreNLP files to Data/CoreNLP\n",
    "if not os.path.exists('Data/CoreNLP'):\n",
    "    coreNLPfilename = 'http://www.cs.cmu.edu/~ark/personas/data/corenlp_plot_summaries.tar'\n",
    "    my_tar = tarfile.open(fileobj=urllib.request.urlopen(coreNLPfilename), mode=\"r|\") \n",
    "    my_tar.extractall(path='./Data/CoreNLP') # specify which folder to extract to\n",
    "    my_tar.close()\n",
    "\n",
    "# Convert every file in directory Data/CoreNLP to xml format\n",
    "raw_dir = 'Data/CoreNLP/corenlp_plot_summaries'\n",
    "extracted_dir = 'Data/CoreNLP/corenlp_plot_summaries_xml'\n",
    "if not os.path.exists(extracted_dir):\n",
    "    os.mkdir(extracted_dir)\n",
    "    for filename in os.listdir(raw_dir):\n",
    "        f = os.path.join(raw_dir, filename) \n",
    "        if os.path.isfile(f):\n",
    "            # Open and store file as xml \n",
    "            with gzip.open(f, 'rb') as f_in:\n",
    "                gz_file = os.path.join(extracted_dir, filename)\n",
    "                with open(gz_file[:-3], 'wb') as f_out:\n",
    "                    f_out.write(f_in.read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoIsNdG539dR"
   },
   "source": [
    "## 2. Pre-processing data\n",
    "\n",
    "### 2.1. Plot summaries\n",
    "\n",
    "`plot_summaries.txt [29 M]`: Plot summaries of 42,306 movies extracted from the November 2, 2012 dump of English-language Wikipedia.  Each line contains the Wikipedia movie ID (which indexes into movie.metadata.tsv) followed by the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z6AUVYUc39dS",
    "outputId": "f909218b-7eaa-40d6-faee-e6937677b4c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23890098</th>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31186339</th>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20663735</th>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231378</th>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595909</th>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34808485</th>\n",
       "      <td>The story is about Reema , a young Muslim scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096473</th>\n",
       "      <td>In 1928 Hollywood, director Leo Andreyev  look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35102018</th>\n",
       "      <td>American Luthier focuses on Randy Parsons’ tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8628195</th>\n",
       "      <td>Abdur Rehman Khan , a middle-aged dry fruit se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040782</th>\n",
       "      <td>1940 - Operation Dynamo has just taken place. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42303 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Summary\n",
       "Wikipedia ID                                                   \n",
       "23890098      Shlykov, a hard-working taxi driver and Lyosha...\n",
       "31186339      The nation of Panem consists of a wealthy Capi...\n",
       "20663735      Poovalli Induchoodan  is sentenced for six yea...\n",
       "2231378       The Lemon Drop Kid , a New York City swindler,...\n",
       "595909        Seventh-day Adventist Church pastor Michael Ch...\n",
       "...                                                         ...\n",
       "34808485      The story is about Reema , a young Muslim scho...\n",
       "1096473       In 1928 Hollywood, director Leo Andreyev  look...\n",
       "35102018      American Luthier focuses on Randy Parsons’ tra...\n",
       "8628195       Abdur Rehman Khan , a middle-aged dry fruit se...\n",
       "6040782       1940 - Operation Dynamo has just taken place. ...\n",
       "\n",
       "[42303 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_path = 'Data/MovieSummaries/plot_summaries.txt'\n",
    "plot_cols = ['Wikipedia ID', 'Summary']\n",
    "plot_df = pd.read_csv(plot_path, sep='\\t', header=None, names=plot_cols, index_col=0)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Hugo: this method stems the words to their lexical root. \n",
    "# Implement Stemming using out of the box Porter algorithm\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "plot_stemmed = [[stemmer.stem(word) for word in sentence.split(\" \")] for sentence in plot_df.iloc[:5].Summary]\n",
    "plot_stemmed = [\" \".join(sentence) for sentence in plot_stemmed]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The word count conversion and tf-idf weighting produce sparse matrices which are destined to be used by NNs. We need something different. \n",
    "# Word count conversion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(strip_accents='ascii',stop_words='english')\n",
    "plot_counts = count_vect.fit_transform(plot_stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF weighting\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "plot_data = tfidf_transformer.fit_transform(plot_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "# from sklearn.preprocessing import normalize\n",
    "# normalize(newsgroups_trainData, norm='l1', axis=0, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8vh3IEW39dS"
   },
   "source": [
    "### 2.2. Movie metadata\n",
    "\n",
    "`movie.metadata.tsv.gz [3.4 M]`: Metadata for 81,741 movies, extracted from the Noverber 4, 2012 dump of Freebase.  Tab-separated; columns:\n",
    "\n",
    "1. Wikipedia movie ID\n",
    "2. Freebase movie ID\n",
    "3. Movie name\n",
    "4. Movie release date\n",
    "5. Movie box office revenue\n",
    "6. Movie runtime\n",
    "7. Movie languages (Freebase ID:name tuples)\n",
    "8. Movie countries (Freebase ID:name tuples)\n",
    "9. Movie genres (Freebase ID:name tuples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "p5NKaQHm39dT",
    "outputId": "3b973e13-6efd-4c48-95a7-0346d5ec753c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freebase ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Box office revenue</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Thriller, Science Fiction, Horror, Adventure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196793</th>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Mystery, Biographical film, Drama, Crime Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28463795</th>\n",
       "      <td>/m/0crgdbh</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>[Norwegian]</td>\n",
       "      <td>[Norway]</td>\n",
       "      <td>[Crime Fiction, Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9363483</th>\n",
       "      <td>/m/0285_cd</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[Thriller, Erotic thriller, Psychological thri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261236</th>\n",
       "      <td>/m/01mrr1</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[German]</td>\n",
       "      <td>[Germany]</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35228177</th>\n",
       "      <td>/m/0j7hxnt</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>2011-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34980460</th>\n",
       "      <td>/m/0g4pl34</td>\n",
       "      <td>Knuckle</td>\n",
       "      <td>2011-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[Ireland, United Kingdom]</td>\n",
       "      <td>[Biographical film, Drama, Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971909</th>\n",
       "      <td>/m/02pygw1</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>1972-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Satire, Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913762</th>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>The Super Dimension Fortress Macross II: Lover...</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>[Japanese]</td>\n",
       "      <td>[Japan]</td>\n",
       "      <td>[Science Fiction, Japanese Movies, Adventure, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12476867</th>\n",
       "      <td>/m/02w7zz8</td>\n",
       "      <td>Spliced</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[Canada]</td>\n",
       "      <td>[Thriller, Horror, Slasher, Teen]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81741 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Freebase ID                                               Name  \\\n",
       "Wikipedia ID                                                                  \n",
       "975900         /m/03vyhn                                     Ghosts of Mars   \n",
       "3196793        /m/08yl5d  Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "28463795      /m/0crgdbh                                        Brun bitter   \n",
       "9363483       /m/0285_cd                                   White Of The Eye   \n",
       "261236         /m/01mrr1                                  A Woman in Flames   \n",
       "...                  ...                                                ...   \n",
       "35228177      /m/0j7hxnt                           Mermaids: The Body Found   \n",
       "34980460      /m/0g4pl34                                            Knuckle   \n",
       "9971909       /m/02pygw1                                  Another Nice Mess   \n",
       "913762         /m/03pcrp  The Super Dimension Fortress Macross II: Lover...   \n",
       "12476867      /m/02w7zz8                                            Spliced   \n",
       "\n",
       "             Release date  Box office revenue  Runtime    Languages  \\\n",
       "Wikipedia ID                                                          \n",
       "975900         2001-08-24          14010832.0     98.0    [English]   \n",
       "3196793        2000-02-16                 NaN     95.0    [English]   \n",
       "28463795             1988                 NaN     83.0  [Norwegian]   \n",
       "9363483              1987                 NaN    110.0    [English]   \n",
       "261236               1983                 NaN    106.0     [German]   \n",
       "...                   ...                 ...      ...          ...   \n",
       "35228177       2011-03-19                 NaN    120.0    [English]   \n",
       "34980460       2011-01-21                 NaN     96.0    [English]   \n",
       "9971909        1972-09-22                 NaN     66.0    [English]   \n",
       "913762         1992-05-21                 NaN    150.0   [Japanese]   \n",
       "12476867             2002                 NaN     86.0    [English]   \n",
       "\n",
       "                               Countries  \\\n",
       "Wikipedia ID                               \n",
       "975900        [United States of America]   \n",
       "3196793       [United States of America]   \n",
       "28463795                        [Norway]   \n",
       "9363483                 [United Kingdom]   \n",
       "261236                         [Germany]   \n",
       "...                                  ...   \n",
       "35228177      [United States of America]   \n",
       "34980460       [Ireland, United Kingdom]   \n",
       "9971909       [United States of America]   \n",
       "913762                           [Japan]   \n",
       "12476867                        [Canada]   \n",
       "\n",
       "                                                         Genres  \n",
       "Wikipedia ID                                                     \n",
       "975900        [Thriller, Science Fiction, Horror, Adventure,...  \n",
       "3196793        [Mystery, Biographical film, Drama, Crime Drama]  \n",
       "28463795                                 [Crime Fiction, Drama]  \n",
       "9363483       [Thriller, Erotic thriller, Psychological thri...  \n",
       "261236                                                  [Drama]  \n",
       "...                                                         ...  \n",
       "35228177                                                [Drama]  \n",
       "34980460                [Biographical film, Drama, Documentary]  \n",
       "9971909                                        [Satire, Comedy]  \n",
       "913762        [Science Fiction, Japanese Movies, Adventure, ...  \n",
       "12476867                      [Thriller, Horror, Slasher, Teen]  \n",
       "\n",
       "[81741 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strip_encoding = lambda x: np.nan if x == '{}' else \\\n",
    "    [w.replace(' Language', '').replace(' language', '') for w in re.findall(r'\"(.*?)\"', x)[1::2]]\n",
    "\n",
    "movie_path = 'Data/MovieSummaries/movie.metadata.tsv'\n",
    "movie_cols = ['Wikipedia ID', 'Freebase ID', 'Name', 'Release date', \n",
    "              'Box office revenue', 'Runtime', 'Languages', 'Countries', 'Genres']\n",
    "movie_df = pd.read_csv(movie_path, sep='\\t', header=None, names=movie_cols, index_col=0, dtype = {'Freebase ID': str})\n",
    "movie_df['Languages'] = movie_df['Languages'].apply(strip_encoding)\n",
    "movie_df['Countries'] = movie_df['Countries'].apply(strip_encoding)\n",
    "movie_df['Genres'] = movie_df['Genres'].apply(strip_encoding)\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMGsQrxV39dT"
   },
   "source": [
    "### 2.3. Character metadata\n",
    "\n",
    "`character.metadata.tsv.gz [14 M]`: Metadata for 450,669 characters aligned to the movies above, extracted from the November 4, 2012 dump of Freebase.  Tab-separated; columns:\n",
    "\n",
    "1. Wikipedia movie ID\n",
    "2. Freebase movie ID\n",
    "3. Movie release date\n",
    "4. Character name\n",
    "5. Actor date of birth\n",
    "6. Actor gender\n",
    "7. Actor height (in meters)\n",
    "8. Actor ethnicity (Freebase ID)\n",
    "9. Actor name\n",
    "10. Actor age at movie release\n",
    "11. Freebase character/actor map ID\n",
    "12. Freebase character ID\n",
    "13. Freebase actor ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "id": "7xdjzblS39dT",
    "outputId": "9c609dff-a8d6-495a-f3c5-7e12ffb2639d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freebase ID</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Character name</th>\n",
       "      <th>Date of birth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Actor name</th>\n",
       "      <th>Actor age at release</th>\n",
       "      <th>Freebase character/map ID</th>\n",
       "      <th>Freebase character ID</th>\n",
       "      <th>Freebase actor ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913762</th>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>Elensh</td>\n",
       "      <td>1970-05</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dorothy Elias-Fahn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0kr406c</td>\n",
       "      <td>/m/0kr406h</td>\n",
       "      <td>/m/0b_vcv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913762</th>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>Hibiki</td>\n",
       "      <td>1965-04-12</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jonathan Fahn</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0kr405_</td>\n",
       "      <td>/m/0kr4090</td>\n",
       "      <td>/m/0bx7_j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28308153</th>\n",
       "      <td>/m/0cp05t9</td>\n",
       "      <td>1957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1941-11-18</td>\n",
       "      <td>M</td>\n",
       "      <td>1.730</td>\n",
       "      <td>/m/02w7gg</td>\n",
       "      <td>David Hemmings</td>\n",
       "      <td>15.0</td>\n",
       "      <td>/m/0g8ngmc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/022g44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28308153</th>\n",
       "      <td>/m/0cp05t9</td>\n",
       "      <td>1957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roberta Paterson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0g8ngmj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0g8ngmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28308153</th>\n",
       "      <td>/m/0cp05t9</td>\n",
       "      <td>1957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John Rogers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0g8ngmw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0btz19d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450669 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Freebase ID Release date              Character name  \\\n",
       "Wikipedia ID                                                        \n",
       "975900         /m/03vyhn   2001-08-24                    Akooshay   \n",
       "975900         /m/03vyhn   2001-08-24  Lieutenant Melanie Ballard   \n",
       "975900         /m/03vyhn   2001-08-24         Desolation Williams   \n",
       "975900         /m/03vyhn   2001-08-24          Sgt Jericho Butler   \n",
       "975900         /m/03vyhn   2001-08-24             Bashira Kincaid   \n",
       "...                  ...          ...                         ...   \n",
       "913762         /m/03pcrp   1992-05-21                      Elensh   \n",
       "913762         /m/03pcrp   1992-05-21                      Hibiki   \n",
       "28308153      /m/0cp05t9         1957                         NaN   \n",
       "28308153      /m/0cp05t9         1957                         NaN   \n",
       "28308153      /m/0cp05t9         1957                         NaN   \n",
       "\n",
       "             Date of birth Gender  Height   Ethnicity          Actor name  \\\n",
       "Wikipedia ID                                                                \n",
       "975900          1958-08-26      F   1.620         NaN      Wanda De Jesus   \n",
       "975900          1974-08-15      F   1.780  /m/044038p  Natasha Henstridge   \n",
       "975900          1969-06-15      M   1.727     /m/0x67            Ice Cube   \n",
       "975900          1967-09-12      M   1.750         NaN       Jason Statham   \n",
       "975900          1977-09-25      F   1.650         NaN         Clea DuVall   \n",
       "...                    ...    ...     ...         ...                 ...   \n",
       "913762             1970-05      F     NaN         NaN  Dorothy Elias-Fahn   \n",
       "913762          1965-04-12      M     NaN         NaN       Jonathan Fahn   \n",
       "28308153        1941-11-18      M   1.730   /m/02w7gg      David Hemmings   \n",
       "28308153               NaN    NaN     NaN         NaN    Roberta Paterson   \n",
       "28308153               NaN    NaN     NaN         NaN         John Rogers   \n",
       "\n",
       "              Actor age at release Freebase character/map ID  \\\n",
       "Wikipedia ID                                                   \n",
       "975900                        42.0                /m/0bgchxw   \n",
       "975900                        27.0                 /m/0jys3m   \n",
       "975900                        32.0                 /m/0jys3g   \n",
       "975900                        33.0                /m/02vchl6   \n",
       "975900                        23.0                /m/02vbb3r   \n",
       "...                            ...                       ...   \n",
       "913762                         NaN                /m/0kr406c   \n",
       "913762                        27.0                /m/0kr405_   \n",
       "28308153                      15.0                /m/0g8ngmc   \n",
       "28308153                       NaN                /m/0g8ngmj   \n",
       "28308153                       NaN                /m/0g8ngmw   \n",
       "\n",
       "             Freebase character ID Freebase actor ID  \n",
       "Wikipedia ID                                          \n",
       "975900                  /m/0bgcj3x        /m/03wcfv7  \n",
       "975900                  /m/0bgchn4         /m/0346l4  \n",
       "975900                  /m/0bgchn_        /m/01vw26l  \n",
       "975900                  /m/0bgchnq         /m/034hyc  \n",
       "975900                  /m/0bgchp9         /m/01y9xg  \n",
       "...                            ...               ...  \n",
       "913762                  /m/0kr406h         /m/0b_vcv  \n",
       "913762                  /m/0kr4090         /m/0bx7_j  \n",
       "28308153                       NaN         /m/022g44  \n",
       "28308153                       NaN        /m/0g8ngmm  \n",
       "28308153                       NaN        /m/0btz19d  \n",
       "\n",
       "[450669 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_path = 'Data/MovieSummaries/character.metadata.tsv'\n",
    "char_cols = ['Wikipedia ID', 'Freebase ID', 'Release date', 'Character name', 'Date of birth', \n",
    "             'Gender', 'Height', 'Ethnicity', 'Actor name', 'Actor age at release', \n",
    "             'Freebase character/map ID', 'Freebase character ID', 'Freebase actor ID']\n",
    "char_df = pd.read_csv(char_path, sep='\\t', header=None, names=char_cols, index_col=0)\n",
    "char_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Name clusters\n",
    "\n",
    "`name.clusters.txt`: 970 unique character names used in at least two different movies, along with 2,666 instances of those types.  The ID field indexes into the Freebase character/actor map ID in character.metadata.tsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Character name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'Baby' Louise</th>\n",
       "      <td>[/m/0c0lv89, /m/0h2cmv_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACP Jai Dixit</th>\n",
       "      <td>[/m/0jx7ny, /m/0220_c2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abigail Chase</th>\n",
       "      <td>[/m/02vcd9h, /m/0k14v6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abraham Lincoln</th>\n",
       "      <td>[/m/0k059l1, /m/0k89pf, /m/02tbdlx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abraham Van Helsing</th>\n",
       "      <td>[/m/0jwq7y, /m/02vc_c7, /m/0jxjq1, /m/0k4llv, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yosemite Sam</th>\n",
       "      <td>[/m/0hynrhr, /m/0hyn6wh, /m/0hynsvw, /m/0hynzf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young Jack</th>\n",
       "      <td>[/m/03jq87t, /m/03jppd0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young Jake</th>\n",
       "      <td>[/m/0hndzk9, /m/0bwsx65]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young Jenny</th>\n",
       "      <td>[/m/0gch316, /m/0c0n9bj]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zack Martin</th>\n",
       "      <td>[/m/0h292b9, /m/0gm2yjy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>970 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               Cluster\n",
       "Character name                                                        \n",
       "'Baby' Louise                                 [/m/0c0lv89, /m/0h2cmv_]\n",
       "ACP Jai Dixit                                  [/m/0jx7ny, /m/0220_c2]\n",
       "Abigail Chase                                  [/m/02vcd9h, /m/0k14v6]\n",
       "Abraham Lincoln                    [/m/0k059l1, /m/0k89pf, /m/02tbdlx]\n",
       "Abraham Van Helsing  [/m/0jwq7y, /m/02vc_c7, /m/0jxjq1, /m/0k4llv, ...\n",
       "...                                                                ...\n",
       "Yosemite Sam         [/m/0hynrhr, /m/0hyn6wh, /m/0hynsvw, /m/0hynzf...\n",
       "Young Jack                                    [/m/03jq87t, /m/03jppd0]\n",
       "Young Jake                                    [/m/0hndzk9, /m/0bwsx65]\n",
       "Young Jenny                                   [/m/0gch316, /m/0c0n9bj]\n",
       "Zack Martin                                   [/m/0h292b9, /m/0gm2yjy]\n",
       "\n",
       "[970 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Data/MovieSummaries/'\n",
    "names_path = path+'name.clusters.txt'\n",
    "names_cols = ['Character name', 'Cluster']\n",
    "names_df = pd.read_csv(names_path, sep='\\t', header=None, names=names_cols, dtype = {'Freebase ID': str})\n",
    "names_df = names_df.groupby('Character name').aggregate(list)\n",
    "names_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. TV Tropes Clusters\n",
    "\n",
    "`tvtropes.clusters.txt`: 72 character types drawn from tvtropes.com, along with 501 instances of those types.  The ID field indexes into the Freebase character/actor map ID in character.metadata.tsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Character name</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Freebase character/map ID</th>\n",
       "      <th>Actor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absent_minded_professor</td>\n",
       "      <td>Professor Philip Brainard</td>\n",
       "      <td>Flubber</td>\n",
       "      <td>/m/0jy9q0</td>\n",
       "      <td>Robin Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absent_minded_professor</td>\n",
       "      <td>Professor Keenbean</td>\n",
       "      <td>Richie Rich</td>\n",
       "      <td>/m/02vchl3</td>\n",
       "      <td>Michael McShane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absent_minded_professor</td>\n",
       "      <td>Dr. Reinhardt Lane</td>\n",
       "      <td>The Shadow</td>\n",
       "      <td>/m/0k6fkc</td>\n",
       "      <td>Ian McKellen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absent_minded_professor</td>\n",
       "      <td>Dr. Harold Medford</td>\n",
       "      <td>Them!</td>\n",
       "      <td>/m/0k6_br</td>\n",
       "      <td>Edmund Gwenn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absent_minded_professor</td>\n",
       "      <td>Daniel Jackson</td>\n",
       "      <td>Stargate</td>\n",
       "      <td>/m/0k3rhh</td>\n",
       "      <td>James Spader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>young_gun</td>\n",
       "      <td>Morgan Earp</td>\n",
       "      <td>Tombstone</td>\n",
       "      <td>/m/0k776f</td>\n",
       "      <td>Bill Paxton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>young_gun</td>\n",
       "      <td>Colorado Ryan</td>\n",
       "      <td>Rio Bravo</td>\n",
       "      <td>/m/0k2kqg</td>\n",
       "      <td>Ricky Nelson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>young_gun</td>\n",
       "      <td>Tom Sawyer</td>\n",
       "      <td>The League of Extraordinary Gentlemen</td>\n",
       "      <td>/m/0k5nsh</td>\n",
       "      <td>Shane West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>young_gun</td>\n",
       "      <td>William H. 'Billy the Kid' Bonney</td>\n",
       "      <td>Young Guns II</td>\n",
       "      <td>/m/03lrjk0</td>\n",
       "      <td>Emilio Estevez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>young_gun</td>\n",
       "      <td>Jake</td>\n",
       "      <td>Silverado</td>\n",
       "      <td>/m/0k39jj</td>\n",
       "      <td>Kevin Costner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Cluster                     Character name  \\\n",
       "0    absent_minded_professor          Professor Philip Brainard   \n",
       "1    absent_minded_professor                 Professor Keenbean   \n",
       "2    absent_minded_professor                 Dr. Reinhardt Lane   \n",
       "3    absent_minded_professor                 Dr. Harold Medford   \n",
       "4    absent_minded_professor                     Daniel Jackson   \n",
       "..                       ...                                ...   \n",
       "496                young_gun                        Morgan Earp   \n",
       "497                young_gun                      Colorado Ryan   \n",
       "498                young_gun                         Tom Sawyer   \n",
       "499                young_gun  William H. 'Billy the Kid' Bonney   \n",
       "500                young_gun                               Jake   \n",
       "\n",
       "                                     Movie Freebase character/map ID  \\\n",
       "0                                  Flubber                 /m/0jy9q0   \n",
       "1                              Richie Rich                /m/02vchl3   \n",
       "2                               The Shadow                 /m/0k6fkc   \n",
       "3                                    Them!                 /m/0k6_br   \n",
       "4                                 Stargate                 /m/0k3rhh   \n",
       "..                                     ...                       ...   \n",
       "496                              Tombstone                 /m/0k776f   \n",
       "497                              Rio Bravo                 /m/0k2kqg   \n",
       "498  The League of Extraordinary Gentlemen                 /m/0k5nsh   \n",
       "499                          Young Guns II                /m/03lrjk0   \n",
       "500                              Silverado                 /m/0k39jj   \n",
       "\n",
       "               Actor  \n",
       "0     Robin Williams  \n",
       "1    Michael McShane  \n",
       "2       Ian McKellen  \n",
       "3       Edmund Gwenn  \n",
       "4       James Spader  \n",
       "..               ...  \n",
       "496      Bill Paxton  \n",
       "497     Ricky Nelson  \n",
       "498       Shane West  \n",
       "499   Emilio Estevez  \n",
       "500    Kevin Costner  \n",
       "\n",
       "[501 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_path = path+'tvtropes.clusters.txt'\n",
    "cluster_cols = ['Cluster', 'Character data']\n",
    "cluster_df = pd.read_csv(cluster_path, sep='\\t', header=None, names=cluster_cols, dtype = {'Freebase ID': str})\n",
    "cluster_df['Character data'] = cluster_df['Character data'].apply(lambda x: ast.literal_eval(x))\n",
    "cluster_df['Character name'] = cluster_df['Character data'].apply(lambda x: x['char'])\n",
    "cluster_df['Movie'] = cluster_df['Character data'].apply(lambda x: x['movie'])\n",
    "cluster_df['Freebase character/map ID'] = cluster_df['Character data'].apply(lambda x: x['id'])\n",
    "cluster_df['Actor'] = cluster_df['Character data'].apply(lambda x: x['actor'])\n",
    "cluster_df.drop('Character data', axis=1, inplace=True)\n",
    "cluster_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now join the TV tropes clusters with movie.metadata so we are able to access movie genre and filter on romance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Character name_x</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Freebase character/map ID</th>\n",
       "      <th>Actor</th>\n",
       "      <th>Freebase ID</th>\n",
       "      <th>Release date_x</th>\n",
       "      <th>Character name_y</th>\n",
       "      <th>Date of birth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>...</th>\n",
       "      <th>Actor age at release</th>\n",
       "      <th>Freebase character ID</th>\n",
       "      <th>Freebase actor ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Release date_y</th>\n",
       "      <th>Box office revenue</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Cluster, Character name_x, Movie, Freebase character/map ID, Actor, Freebase ID, Release date_x, Character name_y, Date of birth, Gender, Height, Ethnicity, Actor name, Actor age at release, Freebase character ID, Freebase actor ID, Name, Release date_y, Box office revenue, Runtime, Languages, Countries, Genres]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Fix this\n",
    "cluster_char = cluster_df.merge(char_df, on='Freebase character/map ID')\n",
    "cluster_char_movie = cluster_char.merge(movie_df, on='Freebase ID')\n",
    "romance_cluster = cluster_char_movie[cluster_char_movie['Genres'].apply(lambda x: 'Roman' in x)]\n",
    "romance_cluster.groupby(romance_cluster['Cluster']).size().sort_values(ascending=False)\n",
    "romance_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1. Analysing romantic genres\n",
    "\n",
    "One notices that there are several types of romantic movies: romantic comedy, romance film, romantic drama. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "romance_genres = ['Romantic comedy', 'Romance Film', 'Romantic drama', 'Romantic fantasy', 'Romantic thriller']\n",
    "is_romantic = lambda i: lambda x: any(y in romance_genres[i] for y in x) if type(x) == list else False\n",
    "romance_movies = movie_df[movie_df['Genres'].apply(is_romantic(slice(0, 5)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Organize by category\n",
    "romantic_comedy = romance_movies.loc[movie_df['Genres'].apply(is_romantic(0))]\n",
    "romantic_film = romance_movies.loc[movie_df['Genres'].apply(is_romantic(1))]\n",
    "romantic_drama = romance_movies.loc[movie_df['Genres'].apply(is_romantic(2))]\n",
    "romantic_fantasy = romance_movies.loc[movie_df['Genres'].apply(is_romantic(3))]\n",
    "romantic_thriller = romance_movies.loc[movie_df['Genres'].apply(is_romantic(4))]\n",
    "\n",
    "print('Roman' , romance_movies.shape[0])\n",
    "print('Romantic comedies: ', romantic_comedy.shape[0], '\\nRomantic films: ', romantic_film.shape[0], '\\nRomantic drama: ', romantic_drama.shape[0], '\\nRomantic fantasy: ', romantic_fantasy.shape[0], '\\nRomantic thriller: ', romantic_thriller.shape[0])\n",
    "print('Total number of films: ', movie_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2. Romantic movies runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Should correct outliers\n",
    "#combined_runtime = pd.DataFrame({'Romantic comedy': romantic_comedy['Runtime'], 'Romance Film': romantic_film['Runtime'], 'Romantic drama': romantic_drama['Runtime'], 'Romantic fantasy': romantic_fantasy['Runtime']})\n",
    "#sns.boxplot(combined_runtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(romantic_comedy['Runtime'], color='blue')\n",
    "ax = sns.kdeplot(romantic_drama['Runtime'], color='green')\n",
    "ax = sns.kdeplot(romantic_film['Runtime'], color='red')\n",
    "ax = sns.kdeplot(romantic_fantasy['Runtime'], color='orange')\n",
    "ax.set_xlim(0,250)\n",
    "ax.legend(['Romantic comedy', 'Romantic drama', 'Romance Film', 'Romantic fantasy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.3. Romantic movies box office revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Does not give a good view\n",
    "#combined_box_office = pd.DataFrame({'Romantic comedy': romantic_comedy['Box office revenue'], 'Romance Film': romantic_film['Box office revenue'], 'Romantic drama': romantic_drama['Box office revenue'], 'Romantic fantasy': romantic_fantasy['Box office revenue']})\n",
    "#sns.boxplot(combined_box_office)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(romantic_comedy['Box office revenue'], log_scale=True, color='blue')\n",
    "ax = sns.kdeplot(romantic_drama['Box office revenue'], log_scale=True, color='green')\n",
    "ax = sns.kdeplot(romantic_film['Box office revenue'], log_scale=True, color='red')\n",
    "ax = sns.kdeplot(romantic_fantasy['Box office revenue'], log_scale=True, color='orange')\n",
    "ax.legend(['Romantic comedy', 'Romantic drama', 'Romance Film', 'Romantic fantasy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.4. Romantic movies countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romantic_comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_countries = lambda x: len(x) if type(x) == list else x\n",
    "romantic_comedy['number_countries'] = romantic_comedy['Countries'].apply(get_countries)\n",
    "romantic_fantasy['number_countries'] = romantic_fantasy['Countries'].apply(get_countries)\n",
    "romantic_film['number_countries'] = romantic_film['Countries'].apply(get_countries)\n",
    "romantic_drama['number_countries'] = romantic_drama['Countries'].apply(get_countries)\n",
    "\n",
    "combined_numb_countries = pd.DataFrame({\n",
    "    'Romantic comedy': romantic_comedy['number_countries'], \n",
    "    'Romance Film': romantic_film['number_countries'], \n",
    "    'Romantic drama': romantic_drama['number_countries'], \n",
    "    'Romantic fantasy': romantic_fantasy['number_countries']})\n",
    "\n",
    "print('Percentage romantic comedy movie countries > 1: ', round(romantic_comedy[romantic_comedy['number_countries']> 1].shape[0]/romantic_comedy.shape[0], 2), '%')\n",
    "print('Other countries can be added in code...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.5. Movie languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get languages whole movie set\n",
    "movies_language = movie_df[movie_df['Languages'].notnull()]\n",
    "languages=movies_language['Languages'].sum()\n",
    "values, counts = np.unique(languages, return_counts=True)\n",
    "print('5 most common languages in movies are: ')\n",
    "print(values[counts.argsort()[-5:][::-1]])\n",
    "\n",
    "#Get languages romantic movies overall\n",
    "romance_movies_lang = romance_movies[romance_movies['Languages'].notnull()]\n",
    "languages_romance = romance_movies_lang.Languages.sum()\n",
    "values, counts = np.unique(languages_romance, return_counts=True)\n",
    "print('5 most common languages in romantic movies: ')\n",
    "print(values[counts.argsort()[-5:][::-1]])\n",
    "\n",
    "rom_com_known = romantic_comedy[romantic_comedy['Languages'].notnull()]\n",
    "languages_romcom = rom_com_known.Languages.sum()\n",
    "values, counts = np.unique(languages_romcom, return_counts=True)\n",
    "print('\\n5 most common languages in romantic comedies: ')\n",
    "print(values[counts.argsort()[-5:][::-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifnIh1uE39dU"
   },
   "source": [
    "### 3.6. CoreNLP Plot summaries\n",
    "\n",
    "#### a) Extracting characters\n",
    "\n",
    "For any character, we want to extract related information (from name clusters, character metadata) as well as actions, characteristics and relations (from CoreNLP). We first extract information from the pre-processed dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Harry Potter's character as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with character Harry Potter :\n",
      "\tMovie IDs: [858575, 667372, 670407, 31941988, 9834441, 667368, 667371, 667361, 667361]\n",
      "\tCharacter IDs: ['/m/0jz6jt', '/m/02tbbh6', '/m/0jz6mq', '/m/0jz6hs', '/m/02tbf6n', '/m/0jz6b0', '/m/0jz6dz', '/m/09lybcb']\n",
      "\tTrope: None\n",
      "Selecting movie ID as example: 31941988\n"
     ]
    }
   ],
   "source": [
    "char_name = 'Harry Potter'\n",
    "movie_ids = list(char_df[char_df['Character name'] == 'Harry Potter'].index)\n",
    "char_ids = names_df.loc[char_name].values[0]\n",
    "trope = cluster_df.loc[cluster_df['Character name'] == char_name]\n",
    "# if trop is empty, set trope to None\n",
    "if trope.empty:\n",
    "    trope = None\n",
    "\n",
    "print('Movies with character', char_name, ':')\n",
    "print('\\tMovie IDs:', movie_ids)\n",
    "print('\\tCharacter IDs:', char_ids)\n",
    "print('\\tTrope:', trope)\n",
    "\n",
    "movie_id = movie_ids[3] \n",
    "print('Selecting movie ID as example:', movie_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extract information from the CoreNLP plot summary analysis. We first extract all parsed sentences from the xml file, which we can view as a tree structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an xml file, we return all of its CoreNLP parsed sentences \n",
    "def get_parsed_sentences(tree):\n",
    "    sentences = []\n",
    "    root = tree.getroot()\n",
    "    for child in tree.iter():\n",
    "        if child.tag == \"parse\":\n",
    "            sentences.append(child.text)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To print xml files as a pretty tree\n",
    "def print_xml_tree(parsed_string):\n",
    "    tree = Tree.fromstring(parsed_string)\n",
    "    tree.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                ROOT                                                 \n",
      "                                                 |                                                    \n",
      "                                                 S                                                   \n",
      "                _________________________________|_________________________________________________   \n",
      "               |             |    |                               VP                               | \n",
      "               |             |    |        _______________________|____                            |  \n",
      "               |             |    |       |                           SBAR                         | \n",
      "               |             |    |       |                            |                           |  \n",
      "               |             |    |       |                            S                           | \n",
      "               |             |    |       |            ________________|_______                    |  \n",
      "               PP            |    |       |           |                        VP                  | \n",
      "  _____________|___          |    |       |           |            ____________|_______            |  \n",
      " |                 NP        |    |       |           |           |                    NP          | \n",
      " |              ___|____     |    |       |           |           |             _______|_______    |  \n",
      " |             NP       |    |    NP      |           NP          |            NP              |   | \n",
      " |       ______|___     |    |    |       |       ____|_____      |     _______|___________    |   |  \n",
      " IN    NNP        POS   NN   ,   NNP     VBZ     DT        NNP   VBZ  NNP     NNP         POS  NN  . \n",
      " |      |          |    |    |    |       |      |          |     |    |       |           |   |   |  \n",
      " In Bellatrix      's vault  ,  Harry discovers the      Horcrux  is Helga Hufflepuff      's cup  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "xml_filename = os.path.join(extracted_dir, '{}.xml'.format(movie_id))\n",
    "tree = ET.parse(xml_filename)\n",
    "parsed_str = get_parsed_sentences(tree)[5]\n",
    "print_xml_tree(parsed_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to extract all character names from the xml file. Note that we aggregate consecutive words tagged as NNP (noun, proper, singular) as the same character name (this assumes that plot summaries never contain two distinct names side by side without delimiting punctuation). This is a reasonable assumption since list of names are almost always separated by commas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_characters(tree):\n",
    "    characters = []\n",
    "    current_word = None\n",
    "    was_person = False\n",
    "    character = ''\n",
    "    for child in tree.iter():\n",
    "        if child.tag == 'word':\n",
    "            current_word = child.text\n",
    "        if child.tag == 'NER' and child.text == 'PERSON':\n",
    "            if was_person:# Continue the character\n",
    "                character += ' ' + current_word\n",
    "            else: # Start the character\n",
    "                character = current_word\n",
    "                was_person = True\n",
    "        if was_person and child.tag == 'NER' and child.text != 'PERSON': # End the character\n",
    "            characters.append(character)\n",
    "            character = ''\n",
    "            was_person = False\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voldemort',\n",
       " 'Albus Dumbledore',\n",
       " 'Severus Snape',\n",
       " 'Dobby',\n",
       " 'Harry Potter',\n",
       " 'Ron',\n",
       " 'Hermione',\n",
       " 'Griphook',\n",
       " 'Harry',\n",
       " 'Ollivander',\n",
       " 'Ollivander',\n",
       " 'Draco Malfoy',\n",
       " 'Malfoy',\n",
       " 'Harry',\n",
       " 'Harry']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = ET.parse(xml_filename)\n",
    "get_characters(tree)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a character in a movie, find all sentences mentioning the character\n",
    "def sentences_with_character(xml_filename, char_name):\n",
    "    char_sentences = []\n",
    "    if os.path.isfile(xml_filename):\n",
    "        sentences = get_parsed_sentences(xml_filename)\n",
    "        char_sentences = [sentence for sentence in sentences if char_name in sentence]\n",
    "    return char_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some characters are sometimes mentioned by their full name, and sometimes by a single name. We wish to obtain a dictionary with keys being the character's full name and values being the number of times their name is mentioned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_name(string, characters):\n",
    "    ''' \n",
    "    Find the longest name of a given character in a list of character names. \n",
    "    Input: \n",
    "        string: character name (partial or full)\n",
    "        characters: list of character names\n",
    "    Output: \n",
    "        full_name: longest name of character found in characters\n",
    "    '''\n",
    "    names = string.split(' ')\n",
    "    max_length = 0\n",
    "    for character in characters:\n",
    "        char_names = character.split(' ')\n",
    "        if set(names) <= set(char_names): \n",
    "            num_names = len(char_names)\n",
    "            if num_names > max_length:\n",
    "                max_length = num_names\n",
    "                full_name = character\n",
    "    return full_name\n",
    "\n",
    "# Helper function: given a list of characters, make a dictionary with all maps (short name : full name)\n",
    "def full_name_dict(characters): \n",
    "    full_names = {}\n",
    "    for character in characters:\n",
    "        full_names[character] = get_full_name(character, characters)\n",
    "    return full_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full name: Harry James Potter\n",
      "All full name pairs: {'Harry Potter': 'Harry James Potter', 'Harry': 'Harry James Potter', 'Lord Voldemort': 'Lord Voldemort', 'Harry James Potter': 'Harry James Potter', 'Dumbledore': 'Albus Dumbledore', 'Albus Dumbledore': 'Albus Dumbledore'}\n"
     ]
    }
   ],
   "source": [
    "characters = ['Harry Potter', 'Harry', 'Lord Voldemort', 'Harry James Potter', 'Dumbledore', 'Albus Dumbledore']\n",
    "print('Full name:', get_full_name('Harry Potter', characters))\n",
    "print('All full name pairs:', full_name_dict(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of characters names, create a dictionary of characters with \n",
    "# keys being their full name and values being the number of times they appear in the list\n",
    "\n",
    "def aggregate_characters(characters):\n",
    "    ''' \n",
    "    Input: list of characters\n",
    "    Output: dictionary of (full name : number of times name is mentioned in list)\n",
    "    Example: ['Harry Potter', 'Voldemort', 'Harry'] -> {'Harry Potter': 2, 'Voldemort': 1}\n",
    "    '''\n",
    "    character_dict = dict()\n",
    "    for character in characters:\n",
    "        full_character = get_full_name(character, characters)\n",
    "        if full_character in character_dict:\n",
    "            character_dict[full_character] += 1\n",
    "        else:\n",
    "            character_dict[full_character] = 1\n",
    "    return character_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Harry James Potter': 3, 'Lord Voldemort': 1, 'Albus Dumbledore': 2}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_characters(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Extracting relationships from CoreNLP \n",
    "\n",
    "We first extract the most mentioned characters in any plot summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a parse tree, extract the (N) most mentioned characters\n",
    "def most_mentioned(tree, N):\n",
    "    '''\n",
    "    Input: \n",
    "        tree: parse tree of the xml file\n",
    "        N: the number of characters to return\n",
    "    Output:\n",
    "        A dictionary of the N characters most mentioned in the movie\n",
    "    '''\n",
    "    characters = get_characters(tree)\n",
    "    character_dict = aggregate_characters(characters)\n",
    "    sorted_characters = sorted(character_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_characters[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harry Potter', 26), ('Voldemort', 21), ('Severus Snape', 11)]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_mentioned(tree, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We cannot extract character interactions directly from the CoreNLP output (?). Instead, we use the number of common mentions of two characters in the same sentence as a proxy for the number of interactions. We first define a method that gets the full name of all characters mentioned in each sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of characters and a string sentence, find the sequence of characters appearing in the sentence\n",
    "def characters_in_sentence(characters, sentence):\n",
    "    '''\n",
    "    Input: \n",
    "        characters: list of characters\n",
    "        sentence: string\n",
    "    Output: \n",
    "        characters_mentioned: list of characters that appear in the sentence\n",
    "        characters: list of remaining characters\n",
    "    Example: characters_in_sentence(['Harry Potter', 'Voldemort', 'Dumbledore'], 'Harry Potter fights Voldemort bravely.')\n",
    "    Output: ['Harry Potter', 'Voldemort'], ['Dumbledore']\n",
    "    '''\n",
    "    characters_mentioned = []\n",
    "    if (len(characters) == 0):\n",
    "            return characters_mentioned, characters\n",
    "    character = characters.pop(0)\n",
    "    while character in sentence:\n",
    "        sentence = sentence.split(character, 1)[1]\n",
    "        characters_mentioned.append(character)\n",
    "        if (len(characters) == 0):\n",
    "            break\n",
    "        character = characters.pop(0)\n",
    "    return characters_mentioned, characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence: {{further2}} {{See also}}  As Lord Voldemort retrieves the Elder Wand from Albus Dumbledore's grave, Severus Snape has become Hogwarts headmaster.\n",
      "Characters: ['Harry Potter', 'Harry', 'Lord Voldemort', 'Harry James Potter', 'Dumbledore', 'Albus Dumbledore']\n",
      "Characters mentioned: []\n",
      "Remaining characters: ['Harry', 'Lord Voldemort', 'Harry James Potter', 'Dumbledore', 'Albus Dumbledore']\n"
     ]
    }
   ],
   "source": [
    "print('First sentence:', sentences[0])\n",
    "print('Characters:', characters[:10])\n",
    "characters_mentioned, characters_rem = characters_in_sentence(characters[:10], sentences[0])\n",
    "print('Characters mentioned:', characters_mentioned)\n",
    "print('Remaining characters:', characters_rem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a method that takes in a movie ID, and outputs the number of common mentions (i.e. interactions) for each pair of characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def character_pairs(movie_id):\n",
    "    ''' \n",
    "    Find all pairs of characters that appear in the same sentence in a movie plot summary. \n",
    "    Input: \n",
    "        movie_id: integer Movie ID\n",
    "    Output:\n",
    "        A list of all character pairs in the movie in decreasing order of frequency\n",
    "    '''\n",
    "    char_pairs = dict()\n",
    "\n",
    "    # Parse xml file and get all characters from plot summary\n",
    "    xml_filename = os.path.join(extracted_dir, '{}.xml'.format(movie_id))\n",
    "    tree = ET.parse(xml_filename)\n",
    "    characters = get_characters(tree)\n",
    "    full_name_map = full_name_dict(characters) # all maps (partial name : full name)\n",
    "\n",
    "    # Split plot summary into sentences\n",
    "    plot_summary = plot_df.loc[movie_id].values[0]\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', plot_summary)\n",
    "\n",
    "    # For each sentence, find the characters mentioned and their full names, then add count for each pair between them\n",
    "    for sentence in sentences:\n",
    "        # Only consider sentences with at least 2 mentioned characters\n",
    "        characters_mentioned, characters = characters_in_sentence(characters, sentence)\n",
    "        if len(characters_mentioned) >= 2: \n",
    "            \n",
    "            # Get full names of each character mentioned, remove doubles\n",
    "            full_mentioned = set([full_name_map[c] for c in characters_mentioned])\n",
    "\n",
    "            # Add count for each pair of characters\n",
    "            pairs = list(itertools.combinations(sorted(full_mentioned), 2))\n",
    "            for pair in pairs:\n",
    "                if pair in char_pairs:\n",
    "                    char_pairs[pair] += 1\n",
    "                else:\n",
    "                    char_pairs[pair] = 1\n",
    "    \n",
    "    # Sort character pairs by number of times they appear together\n",
    "    sorted_pairs = sorted(char_pairs.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Hermione Weasley', 'Ron'), 4),\n",
       " (('Harry Potter', 'Voldemort'), 4),\n",
       " (('Albus Dumbledore', 'Voldemort'), 3),\n",
       " (('Albus Dumbledore', 'Severus Snape'), 2),\n",
       " (('Harry Potter', 'Hermione Weasley'), 2),\n",
       " (('Harry Potter', 'Ron'), 2),\n",
       " (('Nagini', 'Voldemort'), 2),\n",
       " (('Harry Potter', 'Lily'), 2),\n",
       " (('Albus Dumbledore', 'Harry Potter'), 2),\n",
       " (('Severus Snape', 'Voldemort'), 1)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_pairs(movie_id)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a movie ID, find the character pairs with the highest number of interactions (both mentioned in a single sentence).\n",
    "def most_interactions(movie_ID, num_pairs):\n",
    "    # Get all characters in the movie\n",
    "    xml_filename = os.path.join(extracted_dir, '{}.xml'.format(movie_ID))\n",
    "    tree = ET.parse(xml_filename)\n",
    "    characters = get_characters(tree)\n",
    "\n",
    "    # Find the plot summary sentences with at least two characters \n",
    "    plot_summary = plot_df.loc[movie_id].values[0]\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', plot_summary)\n",
    "    \n",
    "\n",
    "    # Find the character pairs with the most interactions\n",
    "    character_pairs = dict()\n",
    "    for sentence in sentences:\n",
    "        characters = get_characters(sentence)\n",
    "        character_pairs = aggregate_characters(characters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to identify the two main characters in a plot summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [254], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[39mreturn\u001b[39;00m pairs\n\u001b[1;32m     28\u001b[0m \u001b[39m# Convert into an array and as a dataframe\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m pairs \u001b[39m=\u001b[39m make_pairs(extracted_dir)\n\u001b[1;32m     30\u001b[0m pairs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(pairs)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)  \n\u001b[1;32m     31\u001b[0m pairs_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(pairs, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mWikipedia ID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mchar1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mchar2\u001b[39m\u001b[39m'\u001b[39m]) \n",
      "Cell \u001b[0;32mIn [254], line 12\u001b[0m, in \u001b[0;36mmake_pairs\u001b[0;34m(extracted_dir)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(f):\n\u001b[1;32m     10\u001b[0m     \u001b[39m# Create characters list for each file \u001b[39;00m\n\u001b[1;32m     11\u001b[0m     characters \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 12\u001b[0m     tree \u001b[39m=\u001b[39m ET\u001b[39m.\u001b[39;49mparse(f)\n\u001b[1;32m     13\u001b[0m     root \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mgetroot()\n\u001b[1;32m     14\u001b[0m     \u001b[39mfor\u001b[39;00m child \u001b[39min\u001b[39;00m tree\u001b[39m.\u001b[39miter():\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/xml/etree/ElementTree.py:1229\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39m\"\"\"Parse XML document into element tree.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \n\u001b[1;32m   1222\u001b[0m \u001b[39m*source* is a filename or file object containing XML data,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \n\u001b[1;32m   1227\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m tree \u001b[39m=\u001b[39m ElementTree()\n\u001b[0;32m-> 1229\u001b[0m tree\u001b[39m.\u001b[39;49mparse(source, parser)\n\u001b[1;32m   1230\u001b[0m \u001b[39mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/xml/etree/ElementTree.py:580\u001b[0m, in \u001b[0;36mElementTree.parse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    574\u001b[0m     parser \u001b[39m=\u001b[39m XMLParser()\n\u001b[1;32m    575\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(parser, \u001b[39m'\u001b[39m\u001b[39m_parse_whole\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    576\u001b[0m         \u001b[39m# The default XMLParser, when it comes from an accelerator,\u001b[39;00m\n\u001b[1;32m    577\u001b[0m         \u001b[39m# can define an internal _parse_whole API for efficiency.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m         \u001b[39m# It can be used to parse the whole source without feeding\u001b[39;00m\n\u001b[1;32m    579\u001b[0m         \u001b[39m# it with chunks.\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_root \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39;49m_parse_whole(source)\n\u001b[1;32m    581\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_root\n\u001b[1;32m    582\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TODO: only consider romantic movies\n",
    "#TODO: Aggregate consecutive entity names inton one\n",
    "extracted_dir = 'Data/CoreNLP/corenlp_plot_summaries_xml'\n",
    "\n",
    "def make_pairs (extracted_dir): \n",
    "  pairs = []\n",
    "  for filename in os.listdir(extracted_dir):\n",
    "      f = os.path.join(extracted_dir, filename) \n",
    "      if os.path.isfile(f):\n",
    "          # Create characters list for each file \n",
    "          characters = []\n",
    "          tree = ET.parse(f)\n",
    "          root = tree.getroot()\n",
    "          for child in tree.iter():\n",
    "              if child.tag == \"word\":\n",
    "                current_word = child.text\n",
    "              if child.tag == \"NER\": \n",
    "                if child.text == \"PERSON\":\n",
    "                  characters.append(current_word)\n",
    "          # Select the two characters which appear most often in the file\n",
    "          values, counts = np.unique(characters, return_counts=True)\n",
    "          two_most_frequent_characters = values[counts.argsort()[-2:][::-1]]\n",
    "          # If there exists two characters, create a pair \n",
    "          if len(two_most_frequent_characters) > 1:\n",
    "            pairs.append([f.replace('Data/CoreNLP/corenlp_plot_summaries_xml/', '').replace('.xml', ''), two_most_frequent_characters[0], two_most_frequent_characters[1]])\n",
    "  return pairs\n",
    "\n",
    "# Convert into an array and as a dataframe\n",
    "pairs = make_pairs(extracted_dir)\n",
    "pairs = np.asarray(pairs).reshape(-1, 3)  \n",
    "pairs_df = pd.DataFrame(pairs, columns=['Wikipedia ID', 'char1', 'char2']) \n",
    "pairs_df                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge pairs dataset with characters \n",
    "char_df['Wikipedia ID'] = char_df['Wikipedia ID'].astype(str)\n",
    "pairs_df['Wikipedia ID'] = pairs_df['Wikipedia ID'].astype(str)\n",
    "pairs_char = pairs_df.merge(char_df, on=\"Wikipedia ID\")\n",
    "\n",
    "# Filter out the nan values\n",
    "pairs_char = pairs_char[~pairs_char['Character name'].isna()]\n",
    "\n",
    "# Create columns which indicates if char1 and char2 are in character name \n",
    "pairs_char['char1_is_in_name'] = pairs_char.apply(lambda x: 1 if x['char1'] in x['Character name'] else 0, axis=1)\n",
    "pairs_char['char2_is_in_name'] = pairs_char.apply(lambda x: 1 if x['char2'] in x['Character name'] else 0, axis=1)\n",
    "pairs_char[pairs_char['char1_is_in_name'] == 1 & pairs_char['char2_is_in_name'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. CoreNLP Analysis\n",
    "\n",
    "To use the powerful CoreNLP model, first [download it](https://stanfordnlp.github.io/CoreNLP/download.html), then cd into the downloaded `stanford-corenlp` directory. If you have Java, you can run the following command to open a CoreNLP shell: \n",
    "\n",
    "\n",
    "`java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer` \n",
    " \n",
    "Now that the shell is running, we can use their models to annotate some sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "nlp.annotate('Barack Obama was born in Hawaii.  He is the president. Obama was elected in 2008.')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
