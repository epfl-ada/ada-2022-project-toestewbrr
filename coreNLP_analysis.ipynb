{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Data Analysis Project\n",
    "**Team**: ToeStewBrr - Alexander Sternfeld, Marguerite Thery, Antoine Bonnet, Hugo Bordereaux\n",
    "\n",
    "**Dataset**: CMU Movie Summary Corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CoreNLP Analysis\n",
    "\n",
    "We first load data files and download the pre-processed dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "from load_data import *\n",
    "from coreNLP_analysis import *\n",
    "\n",
    "download_data(coreNLP=False)\n",
    "plot_df = load_plot_df()\n",
    "movie_df = load_movie_df()\n",
    "char_df = load_char_df()\n",
    "names_df = load_names_df()\n",
    "cluster_df = load_cluster_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Extracting characters\n",
    "\n",
    "For any character, we want to extract related information (from name clusters, character metadata) as well as actions, characteristics and relations (from CoreNLP). We first extract information from the pre-processed dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Harry Potter's character as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_name = 'Harry Potter'\n",
    "movie_ids = list(char_df[char_df['Character name'] == 'Harry Potter']['Wikipedia ID'])\n",
    "char_ids = names_df.loc[char_name].values[0]\n",
    "trope = cluster_df.loc[cluster_df['Character name'] == char_name]\n",
    "# if trop is empty, set trope to None\n",
    "if trope.empty:\n",
    "    trope = None\n",
    "\n",
    "print('Movies with character', char_name, ':')\n",
    "print('\\tMovie IDs:', movie_ids)\n",
    "print('\\tCharacter IDs:', char_ids)\n",
    "print('\\tTrope:', trope)\n",
    "\n",
    "movie_id = movie_ids[3] \n",
    "print('Selecting movie ID as example:', movie_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extract information from the CoreNLP plot summary analysis. Each xml file has a tree structure detailing each word of each sentence as well as the parsed sentence in tree form. We extract all parsed sentences from the xml file, each of which we can view as a tree structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = get_tree(movie_id)\n",
    "parsed_str = get_parsed_sentences(tree)[5]\n",
    "print(parsed_str)\n",
    "print_tree(parsed_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to extract all character names from the xml file. Note that we aggregate consecutive words tagged as NNP (noun, proper, singular) as the same character name (this assumes that plot summaries never contain two distinct names side by side without delimiting punctuation). This is a reasonable assumption since list of names are almost always separated by commas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = get_characters(tree)\n",
    "characters[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some characters are sometimes mentioned by their full name, and sometimes by a partial name (e.g. Harry Potter is most often mentioned as simply Harry). To get a more precise idea of how many times each character is mentioned, we wish to denote each character by their full name, i.e. the longest version of their name that appears in the plot summary. \n",
    "\n",
    "To optimize full name lookup, for each plot summary we construct a dictionary which stores as key every partial name mentioned, and as corresponding values the full name of each character.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_name = 'Albus'\n",
    "full_name = get_full_name(char_name, characters)\n",
    "print('Example: the full name of \"{}\" is \"{}\".'.format(char_name,full_name))\n",
    "print('Full name dictionary:', full_name_dict(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the list of character full names, we can now construct a dictionary with keys being the characters' full name and values being the number of times any version of their name is mentioned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_characters(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract the most mentioned characters in any plot summary, in descending order of frequency. We can then see that Harry Potter is indeed the main character of the movie, as he is mentioned 26 times, more than any other character in the summary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_mentioned(movie_id)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 4.2. Extracting relationships\n",
    "\n",
    " We cannot extract character interactions directly from the CoreNLP output (or can we?). Instead, we use the number of common mentions of two characters in the same sentence as a proxy for the number of interactions. For any movie, we find the number of common mentions (i.e. interactions) for each pair of characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_pairs(movie_id, plot_df)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_interaction = character_pairs(movie_id, plot_df)[0][0]\n",
    "main_interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Extracting main character and interactions\n",
    "\n",
    "We will now use the above code to obtain the main character from every plot summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Get main character and number of mentions for each movie\n",
    "pairs_df = plot_df.copy(deep=True)\n",
    "pairs_df['Main character'] = pairs_df['Wikipedia ID'].apply(most_mentioned)\n",
    "pairs_df['Number of mentions'] = pairs_df['Main character'].apply(lambda x: np.nan if x is None else x[0][1])\n",
    "pairs_df['Main character'] = pairs_df['Main character'].apply(lambda x: np.nan if x is None else x[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also extract the most important pair of characters from every plot summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get main pairs of characters for each movie and number of interactions \n",
    "pairs_df['Main interaction'] = pairs_df['Wikipedia ID'].apply(lambda x: character_pairs(x, plot_df))\n",
    "pairs_df['Number of interactions'] = pairs_df['Main interaction'].apply(lambda x: np.nan if x is None else x[0][1])\n",
    "pairs_df['Main interaction'] = pairs_df['Main interaction'].apply(lambda x: np.nan if x is None else x[0][0])\n",
    "\n",
    "# Store data into csv file\n",
    "pairs_df.to_csv('Data/MovieSummaries/plot_characters.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we've already run this code, we can load the dataframe from a file\n",
    "pairs_df = pd.read_csv('Data/MovieSummaries/plot_characters.csv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge pairs dataset with characters \n",
    "char_df['Wikipedia ID'] = char_df['Wikipedia ID'].astype(str)\n",
    "pairs_df['Wikipedia ID'] = pairs_df['Wikipedia ID'].astype(str)\n",
    "pairs_char = pairs_df.merge(char_df, on=\"Wikipedia ID\")\n",
    "pairs_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. CoreNLP Analysis\n",
    "\n",
    "- Goal: run the coreNLP pipeline with openIE (https://stanfordnlp.github.io/CoreNLP/openie.html) and kbp (https://stanfordnlp.github.io/CoreNLP/kbp.html) annotators. \n",
    "- Recommendation: be careful about memory storage (takes a lot of memory to run!)\n",
    "- Prerequisite: java. \n",
    "- Installation: download CoreNLP model [download it](https://stanfordnlp.github.io/CoreNLP/download.html), then cd into the downloaded `stanford-corenlp` directory. \n",
    "- Data preparation: extract plot summaries for romantic comedies (next step: all romantic movies) into txt files. \n",
    "    - create a filelist containing the name of all the files which need to be process using the following command in your terminal: \n",
    "        - find RomancePlots/*.txt > filelist.txt\n",
    "- Run CoreNLP pipeline via your terminal: \n",
    "    - java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,pos,lemma,ner,parse,coref,depparse,natlog,openie,kbp -coref.md.type RULE -filelist filelist.txt -outputDirectory RomancePlotsOutputs/ -outputFormat xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe with romantic movies and their corresponding plots\n",
    "romance_genres = ['Romantic comedy'] \n",
    "#romance_genres = ['Romantic comedy', 'Romance Film', 'Romantic drama', 'Romantic fantasy', 'Romantic thriller']\n",
    "rom_com_plots = get_plots(romance_genres, movie_df, plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom_com_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all romantic comedies plots into separate txt files to be able to run them through the new coreNLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in rom_com_plots.iterrows():\n",
    "#     with open(\"Data/MovieSummaries/RomancePlots/{}.txt\".format(row['Wikipedia ID']), 'w') as f:\n",
    "#         if type(row['Summary']) == str:\n",
    "#             f.write(row['Summary'])\n",
    "#             f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip \n",
    "with ZipFile('Romance_Data/RomancePlotsOutputs.zip', 'r') as zipObj:\n",
    "   # Extract all the romance plots xml files\n",
    "   zipObj.extractall('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each xml file representing a romantic movie, we extract the kbp title relationship. \n",
    "TODO: Rerun corenlp on the files 43849.txt.xml and 1282593.txt.xml which cannot be parsed as trees. Update the zip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be moved to python file once done\n",
    "# Create a list of tuples containing (movie_id, subject, object) for each kbp triples with title relationship\n",
    "def get_relation_df(DIR, relation_type): \n",
    "    title = []\n",
    "    for filename in os.listdir(DIR):\n",
    "        # Manually deleted files: 43849.txt.xml and 1282593.txt.xml because could not be parsed\n",
    "        if filename != \".DS_Store\" and filename != \"43849.txt.xml\" and filename != \"1282593.txt.xml\":\n",
    "            movie_id = filename[:-8]\n",
    "            title.append(get_relation(movie_id, relation_type))\n",
    "    title_df = pd.DataFrame([item for sublist in title for item in sublist], columns=['Wikipedia ID', 'Subject', 'Title'])\n",
    "    title_df = title_df.groupby(['Wikipedia ID','Subject'])['Title'].apply(', '.join).reset_index()  \n",
    "    return title_df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of relevant relationships to chose from: \n",
    "- per_age\n",
    "- per_alternate_names\n",
    "- per_cause_of_death\n",
    "- per_children\n",
    "- per_cities_of_residence\n",
    "- per_city_of_birth\n",
    "- per_city_of_death\n",
    "- per_countries_of_residence\n",
    "- per_country_of_birth\n",
    "- per_country_of_death\n",
    "- per_date_of_birth\n",
    "- per_date_of_death\n",
    "- per_employee_of\n",
    "- per_member_of\n",
    "- per_origin\n",
    "- per_other_family\n",
    "- per_parents\n",
    "- per_religion\n",
    "- per_schools_attended\n",
    "- per_siblings\n",
    "- per_spouse\n",
    "- per_stateorprovince_of_birth\n",
    "- per_stateorprovince_of_death\n",
    "- per_stateorprovinces_of_residence\n",
    "- per_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = get_relation_df(DIR = 'RomancePlotsOutputs/', relation_type = 'per:title')\n",
    "love_df = get_relation_df(DIR = 'RomancePlotsOutputs/', relation_type = 'per:spouse')\n",
    "death_df = get_relation_df(DIR = 'RomancePlotsOutputs/', relation_type = 'per:cause_of_death')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RomancePlotsOutputs has 1491 readable files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "love_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_df = get_relation_df(DIR = 'RomancePlotsOutputs/', relation_type = 'per:cause_of_death')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8df04c4e7c0125b8c70fc020e0a0390d1dc6940b37b05a71d4f4e35006b35f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
