{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Data Analysis Project\n",
    "**Team**: ToeStewBrr - Alexander Sternfeld, Marguerite Thery, Antoine Bonnet, Hugo Bordereaux\n",
    "\n",
    "**Dataset**: CMU Movie Summary Corpus\n",
    "\n",
    "## Textual Analysis\n",
    "\n",
    "We first load data files and download the pre-processed plot summaries dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "from coreNLP_analysis import *\n",
    "from textual_analysis import *\n",
    "import spacy\n",
    "\n",
    "download_data()\n",
    "plot_df = load_plot_df()\n",
    "movie_df = load_movie_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Remove Stop Words\n",
    "\n",
    "A stop word is a frequently used term that a search engine has been configured to ignore, both while indexing entries for searching and when retrieving them as the result of a search query. Examples of stop words include \"the,\" \"a,\" \"an,\" and \"in.\"\n",
    "We don't want these terms to take up any unnecessary storage space or processing time in our database. By keeping a record of the terms you believe to be stop words, we may easily eliminate them for this reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the plot_df to a new dataframe\n",
    "plot_df_removed = plot_df.copy()\n",
    "#Remove stopwords from the summaries\n",
    "plot_df_removed['Summary'] = plot_df['Summary'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_removed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "words = nlp(\"love\")\n",
    "\n",
    "#Create a column with the similarity of the summaries to each word in words\n",
    "for word in words:\n",
    "        #add empty column\n",
    "        plot_df_removed[word.text] = np.nan\n",
    "        #filling it with the corresponding similarity score\n",
    "        plot_df_removed[word.text] = plot_df_removed['Summary'].apply(lambda x: nlp(' '.join(x)).similarity(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_removed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the dataframe by the similarity score\n",
    "plot_df_removed.sort_values(by='love', ascending=False, inplace=True)\n",
    "plot_df_removed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract love-related words from the summary\n",
    "def extract_love_words(text):\n",
    "    words = nlp(\"love\")\n",
    "    love_words = []\n",
    "    for word in words:\n",
    "        love_words += [token.text for token in nlp(' '.join(text)) if token.similarity(word) > 0.35]\n",
    "    return love_words\n",
    "\n",
    "#Create a column with the love-related words in the summaries\n",
    "plot_df_removed['love_words'] = np.nan\n",
    "plot_df_removed['love_words'][:10] = plot_df_removed['Summary'][:10].apply(extract_love_words)\n",
    "\n",
    "#sort love-related words by similarity to love\n",
    "words = nlp(\"love\")\n",
    "for word in words:\n",
    "    plot_df_removed['love_words'][:10] = plot_df_removed['love_words'][:10].apply(lambda x: sorted(x, key=lambda y: nlp(y).similarity(words)))\n",
    "\n",
    "plot_df_removed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = [('wedding', 1), ('valentine', 1), ('girlfriend',1), ('going out',1), ('hate',0), ('cash',0), ('beautiful',1), ('ugly',0), ('mushroom',0), ('glass',0), ('phone',0), ('bank',0), ('partner',1), ('admiration',1),\n",
    "('dinner',0), ('union',1), ('tender',1) , ('vehicule',0), ('computer',0), ('safety',0), ('kiss',1), ('fun',0), ('nerves',0), ('aggressive',0), ('jealous',1), ('sober',0), ('forgive',0), ('daughter',0), ('punishment',0),\n",
    "('relation',1), ('date',1), ('perfume',0), ('affectionate',1), ('friend',0), ('jewels',0), ('commitment',1), ('passion',1)]\n",
    "\n",
    "#computes similarity score with love for each word in test_words\n",
    "for word in test_words:\n",
    "    print(word[0], nlp(word[0]).similarity(nlp(\"love\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = 0.35\n",
    "\n",
    "#create a dataframe from the array of love-related words\n",
    "love_words = pd.DataFrame(columns=['word', 'love_related'])\n",
    "love_words['word'],love_words['love_related'] = zip(*test_words)\n",
    "#add a column with the similarity score with love\n",
    "love_words['score'] = love_words['word'].apply(lambda x: nlp(x).similarity(nlp(\"love valentine wedding girlfriend\")))\n",
    "#add a column with 1 if the score is above the threshold, 0 otherwise\n",
    "love_words['above_threshold'] = love_words['score'].apply(lambda x: 1 if x > score_threshold else 0)\n",
    "love_words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_score(Truth, Prediction):\n",
    "    TP = Truth.apply(lambda x: 1 if x == 1 and Prediction[x] == 1 else 0).sum()\n",
    "    FP = Truth.apply(lambda x: 1 if x == 0 and Prediction[x] == 1 else 0).sum()\n",
    "    FN = Truth.apply(lambda x: 1 if x == 1 and Prediction[x] == 0 else 0).sum()\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute F1 score of the model\n",
    "compute_f1_score(love_words['love_related'], love_words['above_threshold'])\n",
    "\n",
    "#maximize F1 score by varying the threshold\n",
    "max_f1 = 0\n",
    "max_threshold = 0\n",
    "for i in range(100):\n",
    "    score_threshold = i/100\n",
    "    f1 = compute_f1_score(love_words['love_related'], love_words['above_threshold'])\n",
    "    if f1 > max_f1:\n",
    "        max_f1 = f1\n",
    "        max_threshold = score_threshold\n",
    "\n",
    "print('optimal threshold is', max_threshold)\n",
    "\n",
    "love_words['above_threshold'] = love_words['score'].apply(lambda x: 1 if x > max_threshold else 0)\n",
    "love_words.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge plot_df_removed with movie_df\n",
    "plot_genre_df = plot_df_removed.merge(movie_df, on='Wikipedia ID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a column with a boolean value indicating if the movie is a love movie\n",
    "romance_genres = ['Romantic comedy', 'Romance Film', 'Romantic drama', 'Romantic fantasy', 'Romantic thriller']\n",
    "is_romantic = lambda i: lambda x: any(y in romance_genres[i] for y in x) if type(x) == list else False\n",
    "plot_genre_df.head()\n",
    "plot_genre_df[\"Romantic\"] = plot_genre_df['Genres'].apply(is_romantic(slice(0, 5)))\n",
    "plot_genre_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4569753d6183756236fe9e99db19cdd8e758a6a350619760a2d723ed0ded6724"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
