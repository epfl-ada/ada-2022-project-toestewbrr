{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Data Analysis Project\n",
    "**Team**: ToeStewBrr - Alexander Sternfeld, Marguerite Thery, Antoine Bonnet, Hugo Bordereaux\n",
    "\n",
    "**Dataset**: CMU Movie Summary Corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CoreNLP Analysis\n",
    "\n",
    "We first load data files and download the pre-processed dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "from coreNLP_analysis import *\n",
    "\n",
    "download_data()\n",
    "plot_df = load_plot_df()\n",
    "movie_df = load_movie_df()\n",
    "char_df = load_char_df()\n",
    "names_df = load_names_df()\n",
    "cluster_df = load_cluster_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Extracting characters\n",
    "\n",
    "For any character, we want to extract related information (from name clusters, character metadata) as well as actions, characteristics and relations (from CoreNLP). We first extract information from the pre-processed dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Harry Potter's character as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_name = 'Harry Potter'\n",
    "movie_ids = list(char_df[char_df['Character name'] == 'Harry Potter']['Wikipedia ID'])\n",
    "char_ids = names_df.loc[char_name].values[0]\n",
    "trope = cluster_df.loc[cluster_df['Character name'] == char_name]\n",
    "# if trop is empty, set trope to None\n",
    "if trope.empty:\n",
    "    trope = None\n",
    "\n",
    "print('Movies with character', char_name, ':')\n",
    "print('\\tMovie IDs:', movie_ids)\n",
    "print('\\tCharacter IDs:', char_ids)\n",
    "print('\\tTrope:', trope)\n",
    "\n",
    "movie_id = movie_ids[3] \n",
    "print('Selecting movie ID as example:', movie_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extract information from the CoreNLP plot summary analysis. Each xml file has a tree structure detailing each word of each sentence as well as the parsed sentence in tree form. We extract all parsed sentences from the xml file, each of which we can view as a tree structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = get_tree(movie_id)\n",
    "parsed_str = get_parsed_sentences(tree)[5]\n",
    "print(parsed_str)\n",
    "print_tree(parsed_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to extract all character names from the xml file. Note that we aggregate consecutive words tagged as NNP (noun, proper, singular) as the same character name (this assumes that plot summaries never contain two distinct names side by side without delimiting punctuation). This is a reasonable assumption since list of names are almost always separated by commas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = get_characters(tree)\n",
    "characters[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some characters are sometimes mentioned by their full name, and sometimes by a partial name (e.g. Harry Potter is most often mentioned as simply Harry). To get a more precise idea of how many times each character is mentioned, we wish to denote each character by their full name, i.e. the longest version of their name that appears in the plot summary. \n",
    "\n",
    "To optimize full name lookup, for each plot summary we construct a dictionary which stores as key every partial name mentioned, and as corresponding values the full name of each character.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_name = 'Albus'\n",
    "full_name = get_full_name(char_name, characters)\n",
    "print('Example: the full name of \"{}\" is \"{}\".'.format(char_name,full_name))\n",
    "print('Full name dictionary:', full_name_dict(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the list of character full names, we can now construct a dictionary with keys being the characters' full name and values being the number of times any version of their name is mentioned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_characters(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract the most mentioned characters in any plot summary, in descending order of frequency. We can then see that Harry Potter is indeed the main character of the movie, as he is mentioned 26 times, more than any other character in the summary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_mentioned(movie_id)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 4.2. Extracting relationships\n",
    "\n",
    " We cannot extract character interactions directly from the CoreNLP output (or can we?). Instead, we use the number of common mentions of two characters in the same sentence as a proxy for the number of interactions. For any movie, we find the number of common mentions (i.e. interactions) for each pair of characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_pairs(movie_id, plot_df)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_interaction = character_pairs(movie_id, plot_df)[0][0]\n",
    "main_interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Extracting main character and interactions\n",
    "\n",
    "We will now use the above code to obtain the main character from every plot summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Get main character and number of mentions for each movie\n",
    "pairs_df = plot_df.copy(deep=True)\n",
    "pairs_df['Main character'] = pairs_df['Wikipedia ID'].apply(most_mentioned)\n",
    "pairs_df['Number of mentions'] = pairs_df['Main character'].apply(lambda x: np.nan if x is None else x[0][1])\n",
    "pairs_df['Main character'] = pairs_df['Main character'].apply(lambda x: np.nan if x is None else x[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also extract the most important pair of characters from every plot summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get main pairs of characters for each movie and number of interactions \n",
    "pairs_df['Main interaction'] = pairs_df['Wikipedia ID'].apply(lambda x: character_pairs(x, plot_df))\n",
    "pairs_df['Number of interactions'] = pairs_df['Main interaction'].apply(lambda x: np.nan if x is None else x[0][1])\n",
    "pairs_df['Main interaction'] = pairs_df['Main interaction'].apply(lambda x: np.nan if x is None else x[0][0])\n",
    "\n",
    "# Store data into csv file\n",
    "pairs_df.to_csv('Data/MovieSummaries/plot_characters.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we've already run this code, we can load the dataframe from a file\n",
    "pairs_df = pd.read_csv('Data/MovieSummaries/plot_characters.csv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge pairs dataset with characters \n",
    "char_df['Wikipedia ID'] = char_df['Wikipedia ID'].astype(str)\n",
    "pairs_df['Wikipedia ID'] = pairs_df['Wikipedia ID'].astype(str)\n",
    "pairs_char = pairs_df.merge(char_df, on=\"Wikipedia ID\")\n",
    "pairs_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. CoreNLP Analysis\n",
    "\n",
    "- Prerequisite: java. \n",
    "- Be careful about the memory storage\n",
    "- To use the powerful CoreNLP model, first [download it](https://stanfordnlp.github.io/CoreNLP/download.html), then cd into the downloaded `stanford-corenlp` directory. \n",
    "- Run the coreNLP pipeline with openIE (https://stanfordnlp.github.io/CoreNLP/openie.html) and kbp (https://stanfordnlp.github.io/CoreNLP/kbp.html) annotators. \n",
    "- We extract plot summaries for romantic comedies (next step: all romantic movies) into txt files. \n",
    "- Create a filelist to pass as argument to the command containing the name of all the files which need to be process: \n",
    "    - find RomancePlots/*.txt > filelist.txt\n",
    "- Run the following command via the command line: \n",
    "    - java -mx3g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,pos,lemma,ner,parse,coref,depparse,natlog,openie,kbp -coref.md.type RULE -filelist filelist.txt -outputDirectory RomancePlotsOutputs/ -outputFormat xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the plots of romantic movies\n",
    "romance_genres = ['Romantic comedy'] #, 'Romance Film', 'Romantic drama', 'Romantic fantasy', 'Romantic thriller']\n",
    "is_romantic = lambda i: lambda x: any(y in romance_genres[i] for y in x) if type(x) == list else False\n",
    "romance_com = movie_df[movie_df['Genres'].apply(is_romantic(slice(0, 5)))]\n",
    "rom_com_plots = romance_com.merge(plot_df, on='Wikipedia ID', how='left')[['Wikipedia ID', 'Summary']]\n",
    "rom_com_plots = rom_com_plots[~rom_com_plots['Summary'].isna()]\n",
    "rom_com_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom_com_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all romantic comedies plots into separate txt files to be able to run them through the new coreNLP pipeline. \n",
    "(to delete: once I ran the file, manually add them to corenlp_plot_summaires_xml folder to be able to run function in coreNLP_analysis which use XML_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in rom_com_plots.iterrows():\n",
    "    with open(\"Data/MovieSummaries/RomancePlots/{}.txt\".format(row['Wikipedia ID']), 'w') as f:\n",
    "        if type(row['Summary']) == str:\n",
    "            f.write(row['Summary'])\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a method that takes in a movie ID, and outputs the number of common mentions \n",
    "# (i.e. interactions) for each pair of characters. \n",
    "def get_relation(movie_id, relation_type, confidence_threshold=0.9):\n",
    "    '''\n",
    "    Find all subject and object pairs that have a relation type of relation_type\n",
    "    Input: \n",
    "        movie_id: integer Movie ID\n",
    "        relation_type: full list of relations can be find here https://stanfordnlp.github.io/CoreNLP/kbp.html\n",
    "        confidence_threshold: float between 0 and 1, the minimum confidence of the relation\n",
    "    Output:\n",
    "        relations: a list of tuples (subject, object, relation, confidence)\n",
    "    '''\n",
    "    tree = get_tree(movie_id)\n",
    "    relations = []\n",
    "    isRelationType = False\n",
    "    # Iterate through the tree\n",
    "    for child in tree.iter():\n",
    "        # Once at kbp section, find the triple (subject, relation, object) of the correct relation type\n",
    "        if child.tag == 'kbp':\n",
    "            for triple in child.iter():\n",
    "                if triple.tag == 'triple':\n",
    "                    # Check if confidence level is above threshold\n",
    "                    confidence = float(triple.attrib['confidence'].replace(',', '.'))\n",
    "                    if confidence > confidence_threshold: \n",
    "                        for element in triple.iter():\n",
    "                            # Store the subject \n",
    "                            if element.tag == 'subject':\n",
    "                                for el in element.iter():\n",
    "                                    if el.tag == 'text':\n",
    "                                        subject = el.text\n",
    "                            # Store the relation \n",
    "                            if element.tag == 'relation':\n",
    "                                for el in element.iter():\n",
    "                                    if el.tag == 'text':\n",
    "                                        if el.text == relation_type:\n",
    "                                            isRelationType = True\n",
    "                                            relation = el.text\n",
    "                            # If the relation type is correct, store the triple\n",
    "                            if element.tag == 'object' and isRelationType:\n",
    "                                for el in element.iter():\n",
    "                                    if el.tag == 'text':\n",
    "                                        object = el.text\n",
    "                                        relations.append((subject, object, relation, confidence))\n",
    "                                        isRelationType = False\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_relation(movie_id, 'per:spouse')\n",
    "get_relation(movie_id, 'per:title')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8df04c4e7c0125b8c70fc020e0a0390d1dc6940b37b05a71d4f4e35006b35f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
