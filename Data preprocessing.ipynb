{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Applied Data Analysis Project\n",
    "Team: ToeStewBrr - Alexander Sternfeld, Marguerite Thery, Antoine Bonnet, Hugo Bordereaux\n",
    "\n",
    "Dataset: CMU Movie Summary Corpus\n",
    "\n",
    "### 1. Preprocessing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Temporary configuration: Until we figure out how to extract the tar file directly from the url, please download the file and place it in the Data directory of this project.\n",
    "\n",
    "We first extract all files from the MoviesSummaries tar file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if not os.path.exists('Data/MovieSummaries'):\n",
    "    my_tar = tarfile.open('Data/MovieSummaries.tar.gz') # Can't upload voluminous data to Github\n",
    "    my_tar.extractall('./Data') # specify which folder to extract to\n",
    "    my_tar.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then explore the structure of each of the data files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. plot_summaries.txt [29 M]\n",
    "\n",
    "Plot summaries of 42,306 movies extracted from the November 2, 2012 dump of English-language Wikipedia.  Each line contains the Wikipedia movie ID (which indexes into movie.metadata.tsv) followed by the summary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                        Summary\nWikipedia ID                                                   \n23890098      Shlykov, a hard-working taxi driver and Lyosha...\n31186339      The nation of Panem consists of a wealthy Capi...\n20663735      Poovalli Induchoodan  is sentenced for six yea...\n2231378       The Lemon Drop Kid , a New York City swindler,...\n595909        Seventh-day Adventist Church pastor Michael Ch...\n...                                                         ...\n34808485      The story is about Reema , a young Muslim scho...\n1096473       In 1928 Hollywood, director Leo Andreyev  look...\n35102018      American Luthier focuses on Randy Parsons’ tra...\n8628195       Abdur Rehman Khan , a middle-aged dry fruit se...\n6040782       1940 - Operation Dynamo has just taken place. ...\n\n[42303 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Summary</th>\n    </tr>\n    <tr>\n      <th>Wikipedia ID</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23890098</th>\n      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n    </tr>\n    <tr>\n      <th>31186339</th>\n      <td>The nation of Panem consists of a wealthy Capi...</td>\n    </tr>\n    <tr>\n      <th>20663735</th>\n      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n    </tr>\n    <tr>\n      <th>2231378</th>\n      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n    </tr>\n    <tr>\n      <th>595909</th>\n      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34808485</th>\n      <td>The story is about Reema , a young Muslim scho...</td>\n    </tr>\n    <tr>\n      <th>1096473</th>\n      <td>In 1928 Hollywood, director Leo Andreyev  look...</td>\n    </tr>\n    <tr>\n      <th>35102018</th>\n      <td>American Luthier focuses on Randy Parsons’ tra...</td>\n    </tr>\n    <tr>\n      <th>8628195</th>\n      <td>Abdur Rehman Khan , a middle-aged dry fruit se...</td>\n    </tr>\n    <tr>\n      <th>6040782</th>\n      <td>1940 - Operation Dynamo has just taken place. ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>42303 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_path = 'Data/MovieSummaries/plot_summaries.txt'\n",
    "plot_cols = ['Wikipedia ID', 'Summary']\n",
    "plot_df = pd.read_csv(plot_path, sep='\\t', header=None, names=plot_cols, index_col=0)\n",
    "plot_df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. movie.metadata.tsv.gz [3.4 M]\n",
    "\n",
    "\n",
    "Metadata for 81,741 movies, extracted from the Noverber 4, 2012 dump of Freebase.  Tab-separated; columns:\n",
    "\n",
    "1. Wikipedia movie ID\n",
    "2. Freebase movie ID\n",
    "3. Movie name\n",
    "4. Movie release date\n",
    "5. Movie box office revenue\n",
    "6. Movie runtime\n",
    "7. Movie languages (Freebase ID:name tuples)\n",
    "8. Movie countries (Freebase ID:name tuples)\n",
    "9. Movie genres (Freebase ID:name tuples)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "movie_path = 'Data/MovieSummaries/movie.metadata.tsv'\n",
    "movie_cols = ['Wikipedia ID', 'Freebase ID', 'Name', 'Release date',\n",
    "              'Box office revenue', 'Runtime', 'Languages', 'Countries', 'Genres']\n",
    "movie_df = pd.read_csv(movie_path, sep='\\t', header=None, names=movie_cols, index_col=0)\n",
    "movie_df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. character.metadata.tsv.gz [14 M]\n",
    "\n",
    "Metadata for 450,669 characters aligned to the movies above, extracted from the Noverber 4, 2012 dump of Freebase.  Tab-separated; columns:\n",
    "\n",
    "1. Wikipedia movie ID\n",
    "2. Freebase movie ID\n",
    "3. Movie release date\n",
    "4. Character name\n",
    "5. Actor date of birth\n",
    "6. Actor gender\n",
    "7. Actor height (in meters)\n",
    "8. Actor ethnicity (Freebase ID)\n",
    "9. Actor name\n",
    "10. Actor age at movie release\n",
    "11. Freebase character/actor map ID\n",
    "12. Freebase character ID\n",
    "13. Freebase actor ID\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "char_path = 'Data/MovieSummaries/character.metadata.tsv'\n",
    "char_cols = ['Wikipedia ID', 'Freebase ID', 'Release date', 'Character name', 'Date of birth',\n",
    "             'Gender', 'Height', 'Ethnicity', 'Actor name', 'Actor age at release',\n",
    "             'Freebase character/map ID', 'Freebase character ID', 'Freebase actor ID']\n",
    "char_df = pd.read_csv(char_path, sep='\\t', header=None, names=char_cols, index_col=0)\n",
    "char_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. corenlp_plot_summaries.tar.gz [628 M, separate download]\n",
    "\n",
    "The plot summaries from above, run through the Stanford CoreNLP pipeline (tagging, parsing, NER and coref). Each filename begins with the Wikipedia movie ID (which indexes into movie.metadata.tsv).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "#I uploaded the corenlp_plot_summaries from local\n",
    "directory = './corenlp_plot_summaries'\n",
    "\n",
    "#TODO: Need to extract each file and convert them to xml\n",
    "#For loop to open every file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "  f = os.path.join(directory, filename)\n",
    "  if os.path.isfile(f):\n",
    "    #open and store file as xml\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Use file I already extracted on my computer to run some tests\n",
    "tree = ET.parse('3217.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "print(len(root.findall('.//*governor'))) #use parse or basic-dependencies to have more info\n",
    "#print(root.findall('.//*governor').text())\n",
    "for l in root.findall('.//*NER'):\n",
    "  if len(l.text) > 1:\n",
    "    print(l.text)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
