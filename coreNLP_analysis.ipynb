{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Data Analysis Project\n",
    "**Team**: ToeStewBrr - Alexander Sternfeld, Marguerite Thery, Antoine Bonnet, Hugo Bordereaux\n",
    "\n",
    "**Dataset**: CMU Movie Summary Corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CoreNLP Analysis\n",
    "\n",
    "We first load data files and download the pre-processed dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "from coreNLP_analysis import *\n",
    "\n",
    "download_data()\n",
    "plot_df = load_plot_df()\n",
    "movie_df = load_movie_df()\n",
    "char_df = load_char_df()\n",
    "names_df = load_names_df()\n",
    "cluster_df = load_cluster_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Extracting characters\n",
    "\n",
    "For any character, we want to extract related information (from name clusters, character metadata) as well as actions, characteristics and relations (from CoreNLP). We first extract information from the pre-processed dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Harry Potter's character as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with character Harry Potter :\n",
      "\tMovie IDs: [858575, 667372, 670407, 31941988, 9834441, 667368, 667371, 667361, 667361]\n",
      "\tCharacter IDs: ['/m/0jz6jt', '/m/02tbbh6', '/m/0jz6mq', '/m/0jz6hs', '/m/02tbf6n', '/m/0jz6b0', '/m/0jz6dz', '/m/09lybcb']\n",
      "\tTrope: None\n",
      "Selecting movie ID as example: 31941988\n"
     ]
    }
   ],
   "source": [
    "char_name = 'Harry Potter'\n",
    "movie_ids = list(char_df[char_df['Character name'] == 'Harry Potter']['Wikipedia ID'])\n",
    "char_ids = names_df.loc[char_name].values[0]\n",
    "trope = cluster_df.loc[cluster_df['Character name'] == char_name]\n",
    "# if trop is empty, set trope to None\n",
    "if trope.empty:\n",
    "    trope = None\n",
    "\n",
    "print('Movies with character', char_name, ':')\n",
    "print('\\tMovie IDs:', movie_ids)\n",
    "print('\\tCharacter IDs:', char_ids)\n",
    "print('\\tTrope:', trope)\n",
    "\n",
    "movie_id = movie_ids[3] \n",
    "print('Selecting movie ID as example:', movie_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extract information from the CoreNLP plot summary analysis. Each xml file has a tree structure detailing each word of each sentence as well as the parsed sentence in tree form. We extract all parsed sentences from the xml file, each of which we can view as a tree structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT (S (PP (IN In) (NP (NP (NNP Bellatrix) (POS 's)) (NN vault))) (, ,) (NP (NNP Harry)) (VP (VBZ discovers) (SBAR (S (NP (DT the) (NNP Horcrux)) (VP (VBZ is) (NP (NP (NNP Helga) (NNP Hufflepuff) (POS 's)) (NN cup)))))) (. .))) \n",
      "                                                ROOT                                                 \n",
      "                                                 |                                                    \n",
      "                                                 S                                                   \n",
      "                _________________________________|_________________________________________________   \n",
      "               |             |    |                               VP                               | \n",
      "               |             |    |        _______________________|____                            |  \n",
      "               |             |    |       |                           SBAR                         | \n",
      "               |             |    |       |                            |                           |  \n",
      "               |             |    |       |                            S                           | \n",
      "               |             |    |       |            ________________|_______                    |  \n",
      "               PP            |    |       |           |                        VP                  | \n",
      "  _____________|___          |    |       |           |            ____________|_______            |  \n",
      " |                 NP        |    |       |           |           |                    NP          | \n",
      " |              ___|____     |    |       |           |           |             _______|_______    |  \n",
      " |             NP       |    |    NP      |           NP          |            NP              |   | \n",
      " |       ______|___     |    |    |       |       ____|_____      |     _______|___________    |   |  \n",
      " IN    NNP        POS   NN   ,   NNP     VBZ     DT        NNP   VBZ  NNP     NNP         POS  NN  . \n",
      " |      |          |    |    |    |       |      |          |     |    |       |           |   |   |  \n",
      " In Bellatrix      's vault  ,  Harry discovers the      Horcrux  is Helga Hufflepuff      's cup  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = get_tree(movie_id)\n",
    "parsed_str = get_parsed_sentences(tree)[5]\n",
    "print(parsed_str)\n",
    "print_tree(parsed_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to extract all character names from the xml file. Note that we aggregate consecutive words tagged as NNP (noun, proper, singular) as the same character name (this assumes that plot summaries never contain two distinct names side by side without delimiting punctuation). This is a reasonable assumption since list of names are almost always separated by commas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voldemort',\n",
       " 'Albus Dumbledore',\n",
       " 'Severus Snape',\n",
       " 'Dobby',\n",
       " 'Harry Potter',\n",
       " 'Ron',\n",
       " 'Hermione',\n",
       " 'Griphook',\n",
       " 'Harry',\n",
       " 'Ollivander',\n",
       " 'Ollivander',\n",
       " 'Draco Malfoy',\n",
       " 'Malfoy',\n",
       " 'Harry',\n",
       " 'Harry']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = get_characters(tree)\n",
    "characters[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some characters are sometimes mentioned by their full name, and sometimes by a partial name (e.g. Harry Potter is most often mentioned as simply Harry). To get a more precise idea of how many times each character is mentioned, we wish to denote each character by their full name, i.e. the longest version of their name that appears in the plot summary. \n",
    "\n",
    "To optimize full name lookup, for each plot summary we construct a dictionary which stores as key every partial name mentioned, and as corresponding values the full name of each character.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: the full name of \"Albus\" is \"Albus Dumbledore\".\n",
      "Full name dictionary: {'Voldemort': 'Voldemort', 'Albus Dumbledore': 'Albus Dumbledore', 'Severus Snape': 'Severus Snape', 'Dobby': 'Dobby', 'Harry Potter': 'Harry Potter', 'Ron': 'Ron', 'Hermione': 'Hermione Weasley', 'Griphook': 'Griphook', 'Harry': 'Harry Potter', 'Ollivander': 'Ollivander', 'Draco Malfoy': 'Draco Malfoy', 'Malfoy': 'Draco Malfoy', 'Helga Hufflepuff': 'Helga Hufflepuff', 'Rowena Ravenclaw': 'Rowena Ravenclaw', 'Hogsmeade': 'Hogsmeade', 'Aberforth Dumbledore': 'Aberforth Dumbledore', 'Ariana': 'Ariana', 'Neville Longbottom': 'Neville Longbottom', 'Snape': 'Severus Snape', 'Minerva McGonagall': 'Minerva McGonagall', 'Luna Lovegood': 'Luna Lovegood', 'Helena Ravenclaw': 'Helena Ravenclaw', 'Gregory Goyle': 'Gregory Goyle', 'Blaise Zabini': 'Blaise Zabini', 'Nagini': 'Nagini', 'Fred': 'Fred', 'Lily': 'Lily', 'James': 'James', 'Dumbledore': 'Albus Dumbledore', 'Neville': 'Neville Longbottom', 'Molly Weasley': 'Molly Weasley', 'Ginny Potter': 'Ginny Potter', 'Hermione Weasley': 'Hermione Weasley'}\n"
     ]
    }
   ],
   "source": [
    "char_name = 'Albus'\n",
    "full_name = get_full_name(char_name, characters)\n",
    "print('Example: the full name of \"{}\" is \"{}\".'.format(char_name,full_name))\n",
    "print('Full name dictionary:', full_name_dict(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the list of character full names, we can now construct a dictionary with keys being the characters' full name and values being the number of times any version of their name is mentioned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Voldemort': 21,\n",
       " 'Albus Dumbledore': 5,\n",
       " 'Severus Snape': 11,\n",
       " 'Dobby': 1,\n",
       " 'Harry Potter': 26,\n",
       " 'Ron': 6,\n",
       " 'Hermione Weasley': 6,\n",
       " 'Griphook': 3,\n",
       " 'Ollivander': 2,\n",
       " 'Draco Malfoy': 3,\n",
       " 'Helga Hufflepuff': 1,\n",
       " 'Rowena Ravenclaw': 1,\n",
       " 'Hogsmeade': 1,\n",
       " 'Aberforth Dumbledore': 1,\n",
       " 'Ariana': 1,\n",
       " 'Neville Longbottom': 3,\n",
       " 'Minerva McGonagall': 1,\n",
       " 'Luna Lovegood': 1,\n",
       " 'Helena Ravenclaw': 1,\n",
       " 'Gregory Goyle': 1,\n",
       " 'Blaise Zabini': 1,\n",
       " 'Nagini': 3,\n",
       " 'Fred': 1,\n",
       " 'Lily': 2,\n",
       " 'James': 1,\n",
       " 'Molly Weasley': 1,\n",
       " 'Ginny Potter': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_characters(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract the most mentioned characters in any plot summary, in descending order of frequency. We can then see that Harry Potter is indeed the main character of the movie, as he is mentioned 26 times, more than any other character in the summary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harry Potter', 26),\n",
       " ('Voldemort', 21),\n",
       " ('Severus Snape', 11),\n",
       " ('Ron', 6),\n",
       " ('Hermione Weasley', 6),\n",
       " ('Albus Dumbledore', 5),\n",
       " ('Griphook', 3),\n",
       " ('Draco Malfoy', 3),\n",
       " ('Neville Longbottom', 3),\n",
       " ('Nagini', 3)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_mentioned(movie_id)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 4.2. Extracting relationships\n",
    "\n",
    " We cannot extract character interactions directly from the CoreNLP output (or can we?). Instead, we use the number of common mentions of two characters in the same sentence as a proxy for the number of interactions. For any movie, we find the number of common mentions (i.e. interactions) for each pair of characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Hermione Weasley', 'Ron'), 4),\n",
       " (('Harry Potter', 'Voldemort'), 4),\n",
       " (('Albus Dumbledore', 'Voldemort'), 3),\n",
       " (('Albus Dumbledore', 'Severus Snape'), 2),\n",
       " (('Harry Potter', 'Hermione Weasley'), 2),\n",
       " (('Harry Potter', 'Ron'), 2),\n",
       " (('Nagini', 'Voldemort'), 2),\n",
       " (('Harry Potter', 'Lily'), 2),\n",
       " (('Albus Dumbledore', 'Harry Potter'), 2),\n",
       " (('Severus Snape', 'Voldemort'), 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_pairs(movie_id, plot_df)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Hermione Weasley', 'Ron')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_interaction = character_pairs(movie_id, plot_df)[0][0]\n",
    "main_interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Extracting main character and interactions\n",
    "\n",
    "We will now use the above code to obtain the main character from every plot summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get main character and number of mentions for each movie\n",
    "pairs_df = plot_df.copy(deep=True)\n",
    "pairs_df['Main character'] = pairs_df['Wikipedia ID'].apply(most_mentioned)\n",
    "pairs_df['Number of mentions'] = pairs_df['Main character'].apply(lambda x: np.nan if x is None else x[0][1])\n",
    "pairs_df['Main character'] = pairs_df['Main character'].apply(lambda x: np.nan if x is None else x[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also extract the most important pair of characters from every plot summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get main pairs of characters for each movie and number of interactions \n",
    "pairs_df['Main interaction'] = pairs_df['Wikipedia ID'].apply(lambda x: character_pairs(x, plot_df))\n",
    "pairs_df['Number of interactions'] = pairs_df['Main interaction'].apply(lambda x: np.nan if x is None else x[0][1])\n",
    "pairs_df['Main interaction'] = pairs_df['Main interaction'].apply(lambda x: np.nan if x is None else x[0][0])\n",
    "\n",
    "# Store data into csv file\n",
    "pairs_df.to_csv('Data/MovieSummaries/plot_characters.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we've already run this code, we can load the dataframe from a file\n",
    "pairs_df = pd.read_csv('Data/MovieSummaries/plot_characters.csv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Main character</th>\n",
       "      <th>Number of mentions</th>\n",
       "      <th>Main interaction</th>\n",
       "      <th>Number of interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>Shlykov</td>\n",
       "      <td>1.0</td>\n",
       "      <td>('Lyosha', 'Shlykov')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "      <td>Katniss</td>\n",
       "      <td>18.0</td>\n",
       "      <td>('Katniss', 'Peeta Mellark')</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "      <td>Maranchery Karunakara Menon</td>\n",
       "      <td>9.0</td>\n",
       "      <td>('Manapally Madhavan Nambiar', 'judge Menon')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "      <td>Charley</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "      <td>Lindy</td>\n",
       "      <td>7.0</td>\n",
       "      <td>('Azaria', 'Lindy')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42298</th>\n",
       "      <td>34808485</td>\n",
       "      <td>The story is about Reema , a young Muslim scho...</td>\n",
       "      <td>Reema</td>\n",
       "      <td>1.0</td>\n",
       "      <td>('Muslim', 'Reema')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42299</th>\n",
       "      <td>1096473</td>\n",
       "      <td>In 1928 Hollywood, director Leo Andreyev  look...</td>\n",
       "      <td>Leo Andreyev</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42300</th>\n",
       "      <td>35102018</td>\n",
       "      <td>American Luthier focuses on Randy Parsons’ tra...</td>\n",
       "      <td>Randy Parsons</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42301</th>\n",
       "      <td>8628195</td>\n",
       "      <td>Abdur Rehman Khan , a middle-aged dry fruit se...</td>\n",
       "      <td>Abdur Rehman Khan</td>\n",
       "      <td>9.0</td>\n",
       "      <td>('Abdur Rehman Khan', 'Amina')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42302</th>\n",
       "      <td>6040782</td>\n",
       "      <td>1940 - Operation Dynamo has just taken place. ...</td>\n",
       "      <td>George Mainwaring</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42303 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia ID                                            Summary  \\\n",
       "0          23890098  Shlykov, a hard-working taxi driver and Lyosha...   \n",
       "1          31186339  The nation of Panem consists of a wealthy Capi...   \n",
       "2          20663735  Poovalli Induchoodan  is sentenced for six yea...   \n",
       "3           2231378  The Lemon Drop Kid , a New York City swindler,...   \n",
       "4            595909  Seventh-day Adventist Church pastor Michael Ch...   \n",
       "...             ...                                                ...   \n",
       "42298      34808485  The story is about Reema , a young Muslim scho...   \n",
       "42299       1096473  In 1928 Hollywood, director Leo Andreyev  look...   \n",
       "42300      35102018  American Luthier focuses on Randy Parsons’ tra...   \n",
       "42301       8628195  Abdur Rehman Khan , a middle-aged dry fruit se...   \n",
       "42302       6040782  1940 - Operation Dynamo has just taken place. ...   \n",
       "\n",
       "                    Main character  Number of mentions  \\\n",
       "0                          Shlykov                 1.0   \n",
       "1                          Katniss                18.0   \n",
       "2      Maranchery Karunakara Menon                 9.0   \n",
       "3                          Charley                18.0   \n",
       "4                            Lindy                 7.0   \n",
       "...                            ...                 ...   \n",
       "42298                        Reema                 1.0   \n",
       "42299                 Leo Andreyev                 7.0   \n",
       "42300                Randy Parsons                 4.0   \n",
       "42301            Abdur Rehman Khan                 9.0   \n",
       "42302            George Mainwaring                 9.0   \n",
       "\n",
       "                                    Main interaction  Number of interactions  \n",
       "0                              ('Lyosha', 'Shlykov')                     1.0  \n",
       "1                       ('Katniss', 'Peeta Mellark')                     2.0  \n",
       "2      ('Manapally Madhavan Nambiar', 'judge Menon')                     1.0  \n",
       "3                                                NaN                     NaN  \n",
       "4                                ('Azaria', 'Lindy')                     1.0  \n",
       "...                                              ...                     ...  \n",
       "42298                            ('Muslim', 'Reema')                     1.0  \n",
       "42299                                            NaN                     NaN  \n",
       "42300                                            NaN                     NaN  \n",
       "42301                 ('Abdur Rehman Khan', 'Amina')                     1.0  \n",
       "42302                                            NaN                     NaN  \n",
       "\n",
       "[42303 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Main character</th>\n",
       "      <th>Number of mentions</th>\n",
       "      <th>Main interaction</th>\n",
       "      <th>Number of interactions</th>\n",
       "      <th>Freebase ID</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Character name</th>\n",
       "      <th>Date of birth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Actor name</th>\n",
       "      <th>Actor age at release</th>\n",
       "      <th>Freebase character/map ID</th>\n",
       "      <th>Freebase character ID</th>\n",
       "      <th>Freebase actor ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>Shlykov</td>\n",
       "      <td>1.0</td>\n",
       "      <td>('Lyosha', 'Shlykov')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/m/076w2lb</td>\n",
       "      <td>1990-09-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natalia Koliakanova</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0gby7pd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0gby7pj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>Shlykov</td>\n",
       "      <td>1.0</td>\n",
       "      <td>('Lyosha', 'Shlykov')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/m/076w2lb</td>\n",
       "      <td>1990-09-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1951-04-14</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pyotr Mamonov</td>\n",
       "      <td>39.0</td>\n",
       "      <td>/m/07lld1w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/06trhc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>Shlykov</td>\n",
       "      <td>1.0</td>\n",
       "      <td>('Lyosha', 'Shlykov')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/m/076w2lb</td>\n",
       "      <td>1990-09-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1919-10-08</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Hal Singer</td>\n",
       "      <td>70.0</td>\n",
       "      <td>/m/0gc0hbm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/01n4sp6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>Shlykov</td>\n",
       "      <td>1.0</td>\n",
       "      <td>('Lyosha', 'Shlykov')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/m/076w2lb</td>\n",
       "      <td>1990-09-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1926-10-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vladimir Kashpur</td>\n",
       "      <td>63.0</td>\n",
       "      <td>/m/0gc3tz0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/08087zv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>Shlykov</td>\n",
       "      <td>1.0</td>\n",
       "      <td>('Lyosha', 'Shlykov')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/m/076w2lb</td>\n",
       "      <td>1990-09-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pyotr Zaychenko</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0gcjqgq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0clzzrg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308480</th>\n",
       "      <td>6040782</td>\n",
       "      <td>1940 - Operation Dynamo has just taken place. ...</td>\n",
       "      <td>George Mainwaring</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0fm00m</td>\n",
       "      <td>1971-03-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1920-01-09</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0g96wd</td>\n",
       "      <td>Clive Dunn</td>\n",
       "      <td>51.0</td>\n",
       "      <td>/m/0jwx5f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/01vct06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308481</th>\n",
       "      <td>6040782</td>\n",
       "      <td>1940 - Operation Dynamo has just taken place. ...</td>\n",
       "      <td>George Mainwaring</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0fm00m</td>\n",
       "      <td>1971-03-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1897-03-25</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John Laurie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0jwx5l</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/057hy_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308482</th>\n",
       "      <td>6040782</td>\n",
       "      <td>1940 - Operation Dynamo has just taken place. ...</td>\n",
       "      <td>George Mainwaring</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0fm00m</td>\n",
       "      <td>1971-03-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1896-01-07</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnold Ridley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0jwx5x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/02t7zg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308483</th>\n",
       "      <td>6040782</td>\n",
       "      <td>1940 - Operation Dynamo has just taken place. ...</td>\n",
       "      <td>George Mainwaring</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0fm00m</td>\n",
       "      <td>1971-03-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1946-02-16</td>\n",
       "      <td>M</td>\n",
       "      <td>1.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ian Lavender</td>\n",
       "      <td>25.0</td>\n",
       "      <td>/m/0jwx61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/04xs2l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308484</th>\n",
       "      <td>6040782</td>\n",
       "      <td>1940 - Operation Dynamo has just taken place. ...</td>\n",
       "      <td>George Mainwaring</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0fm00m</td>\n",
       "      <td>1971-03-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1916-08-20</td>\n",
       "      <td>M</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bernard Archard</td>\n",
       "      <td>54.0</td>\n",
       "      <td>/m/0jwx66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/073y78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308485 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia ID                                            Summary  \\\n",
       "0          23890098  Shlykov, a hard-working taxi driver and Lyosha...   \n",
       "1          23890098  Shlykov, a hard-working taxi driver and Lyosha...   \n",
       "2          23890098  Shlykov, a hard-working taxi driver and Lyosha...   \n",
       "3          23890098  Shlykov, a hard-working taxi driver and Lyosha...   \n",
       "4          23890098  Shlykov, a hard-working taxi driver and Lyosha...   \n",
       "...             ...                                                ...   \n",
       "308480      6040782  1940 - Operation Dynamo has just taken place. ...   \n",
       "308481      6040782  1940 - Operation Dynamo has just taken place. ...   \n",
       "308482      6040782  1940 - Operation Dynamo has just taken place. ...   \n",
       "308483      6040782  1940 - Operation Dynamo has just taken place. ...   \n",
       "308484      6040782  1940 - Operation Dynamo has just taken place. ...   \n",
       "\n",
       "           Main character  Number of mentions       Main interaction  \\\n",
       "0                 Shlykov                 1.0  ('Lyosha', 'Shlykov')   \n",
       "1                 Shlykov                 1.0  ('Lyosha', 'Shlykov')   \n",
       "2                 Shlykov                 1.0  ('Lyosha', 'Shlykov')   \n",
       "3                 Shlykov                 1.0  ('Lyosha', 'Shlykov')   \n",
       "4                 Shlykov                 1.0  ('Lyosha', 'Shlykov')   \n",
       "...                   ...                 ...                    ...   \n",
       "308480  George Mainwaring                 9.0                    NaN   \n",
       "308481  George Mainwaring                 9.0                    NaN   \n",
       "308482  George Mainwaring                 9.0                    NaN   \n",
       "308483  George Mainwaring                 9.0                    NaN   \n",
       "308484  George Mainwaring                 9.0                    NaN   \n",
       "\n",
       "        Number of interactions Freebase ID Release date Character name  \\\n",
       "0                          1.0  /m/076w2lb   1990-09-07            NaN   \n",
       "1                          1.0  /m/076w2lb   1990-09-07            NaN   \n",
       "2                          1.0  /m/076w2lb   1990-09-07            NaN   \n",
       "3                          1.0  /m/076w2lb   1990-09-07            NaN   \n",
       "4                          1.0  /m/076w2lb   1990-09-07            NaN   \n",
       "...                        ...         ...          ...            ...   \n",
       "308480                     NaN   /m/0fm00m   1971-03-12            NaN   \n",
       "308481                     NaN   /m/0fm00m   1971-03-12            NaN   \n",
       "308482                     NaN   /m/0fm00m   1971-03-12            NaN   \n",
       "308483                     NaN   /m/0fm00m   1971-03-12            NaN   \n",
       "308484                     NaN   /m/0fm00m   1971-03-12            NaN   \n",
       "\n",
       "       Date of birth Gender  Height  Ethnicity           Actor name  \\\n",
       "0                NaN    NaN     NaN        NaN  Natalia Koliakanova   \n",
       "1         1951-04-14      M     NaN        NaN        Pyotr Mamonov   \n",
       "2         1919-10-08      M     NaN    /m/0x67           Hal Singer   \n",
       "3         1926-10-26    NaN     NaN        NaN     Vladimir Kashpur   \n",
       "4                NaN    NaN     NaN        NaN      Pyotr Zaychenko   \n",
       "...              ...    ...     ...        ...                  ...   \n",
       "308480    1920-01-09      M     NaN  /m/0g96wd           Clive Dunn   \n",
       "308481    1897-03-25      M     NaN        NaN          John Laurie   \n",
       "308482    1896-01-07      M     NaN        NaN        Arnold Ridley   \n",
       "308483    1946-02-16      M    1.77        NaN         Ian Lavender   \n",
       "308484    1916-08-20      M    1.80        NaN      Bernard Archard   \n",
       "\n",
       "        Actor age at release Freebase character/map ID Freebase character ID  \\\n",
       "0                        NaN                /m/0gby7pd                   NaN   \n",
       "1                       39.0                /m/07lld1w                   NaN   \n",
       "2                       70.0                /m/0gc0hbm                   NaN   \n",
       "3                       63.0                /m/0gc3tz0                   NaN   \n",
       "4                        NaN                /m/0gcjqgq                   NaN   \n",
       "...                      ...                       ...                   ...   \n",
       "308480                  51.0                 /m/0jwx5f                   NaN   \n",
       "308481                   NaN                 /m/0jwx5l                   NaN   \n",
       "308482                   NaN                 /m/0jwx5x                   NaN   \n",
       "308483                  25.0                 /m/0jwx61                   NaN   \n",
       "308484                  54.0                 /m/0jwx66                   NaN   \n",
       "\n",
       "       Freebase actor ID  \n",
       "0             /m/0gby7pj  \n",
       "1              /m/06trhc  \n",
       "2             /m/01n4sp6  \n",
       "3             /m/08087zv  \n",
       "4             /m/0clzzrg  \n",
       "...                  ...  \n",
       "308480        /m/01vct06  \n",
       "308481         /m/057hy_  \n",
       "308482         /m/02t7zg  \n",
       "308483         /m/04xs2l  \n",
       "308484         /m/073y78  \n",
       "\n",
       "[308485 rows x 18 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge pairs dataset with characters \n",
    "char_df['Wikipedia ID'] = char_df['Wikipedia ID'].astype(str)\n",
    "pairs_df['Wikipedia ID'] = pairs_df['Wikipedia ID'].astype(str)\n",
    "pairs_char = pairs_df.merge(char_df, on=\"Wikipedia ID\")\n",
    "pairs_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. CoreNLP Analysis\n",
    "\n",
    "- Prerequisite: java. \n",
    "- Be careful about the memory storage\n",
    "- To use the powerful CoreNLP model, first [download it](https://stanfordnlp.github.io/CoreNLP/download.html), then cd into the downloaded `stanford-corenlp` directory. \n",
    "- Run the coreNLP pipeline with openIE (https://stanfordnlp.github.io/CoreNLP/openie.html) and kbp (https://stanfordnlp.github.io/CoreNLP/kbp.html) annotators. \n",
    "- We extract plot summaries for romantic comedies (next step: all romantic movies) into txt files. \n",
    "- Create a filelist to pass as argument to the command containing the name of all the files which need to be process: \n",
    "    - find RomancePlots/*.txt > filelist.txt\n",
    "- Run the following command via the command line: \n",
    "    - java -mx3g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,pos,lemma,ner,parse,coref,depparse,natlog,openie,kbp -coref.md.type RULE -filelist filelist.txt -outputDirectory RomancePlotsOutputs/ -outputFormat xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the plots of romantic movies\n",
    "romance_genres = ['Romantic comedy'] #, 'Romance Film', 'Romantic drama', 'Romantic fantasy', 'Romantic thriller']\n",
    "is_romantic = lambda i: lambda x: any(y in romance_genres[i] for y in x) if type(x) == list else False\n",
    "romance_com = movie_df[movie_df['Genres'].apply(is_romantic(slice(0, 5)))]\n",
    "rom_com_plots = romance_com.merge(plot_df, on='Wikipedia ID', how='left')[['Wikipedia ID', 'Summary']]\n",
    "rom_com_plots = rom_com_plots[~rom_com_plots['Summary'].isna()]\n",
    "rom_com_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom_com_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all romantic comedies plots into separate txt files to be able to run them through the new coreNLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in rom_com_plots.iterrows():\n",
    "    with open(\"Data/MovieSummaries/RomancePlots/{}.txt\".format(row['Wikipedia ID']), 'w') as f:\n",
    "        if type(row['Summary']) == str:\n",
    "            f.write(row['Summary'])\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a method that takes in a movie ID, and outputs the number of common mentions \n",
    "# (i.e. interactions) for each pair of characters. \n",
    "def get_relation(movie_id, relation_type, confidence_threshold=0.9):\n",
    "    '''\n",
    "    Find all subject and object pairs that have a relation type of relation_type\n",
    "    Input: \n",
    "        movie_id: integer Movie ID\n",
    "        relation_type: full list of relations can be find here https://stanfordnlp.github.io/CoreNLP/kbp.html\n",
    "        confidence_threshold: float between 0 and 1, the minimum confidence of the relation\n",
    "    Output:\n",
    "        relations: a list of tuples (subject, object, relation, confidence)\n",
    "    '''\n",
    "    tree = get_tree(movie_id)\n",
    "    relations = []\n",
    "    isRelationType = False\n",
    "    # Iterate through the tree\n",
    "    for child in tree.iter():\n",
    "        # Once at kbp section, find the triple (subject, relation, object) of the correct relation type\n",
    "        if child.tag == 'kbp':\n",
    "            for triple in child.iter():\n",
    "                if triple.tag == 'triple':\n",
    "                    # Check if confidence level is above threshold\n",
    "                    confidence = float(triple.attrib['confidence'].replace(',', '.'))\n",
    "                    if confidence > confidence_threshold: \n",
    "                        for element in triple.iter():\n",
    "                            # Store the subject \n",
    "                            if element.tag == 'subject':\n",
    "                                for el in element.iter():\n",
    "                                    if el.tag == 'text':\n",
    "                                        subject = el.text\n",
    "                            # Store the relation \n",
    "                            if element.tag == 'relation':\n",
    "                                for el in element.iter():\n",
    "                                    if el.tag == 'text':\n",
    "                                        if el.text == relation_type:\n",
    "                                            isRelationType = True\n",
    "                                            relation = el.text\n",
    "                            # If the relation type is correct, store the triple\n",
    "                            if element.tag == 'object' and isRelationType:\n",
    "                                for el in element.iter():\n",
    "                                    if el.tag == 'text':\n",
    "                                        object = el.text\n",
    "                                        relations.append((subject, object, relation, confidence))\n",
    "                                        isRelationType = False\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_relation(movie_id, 'per:spouse')\n",
    "get_relation(movie_id, 'per:title')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8df04c4e7c0125b8c70fc020e0a0390d1dc6940b37b05a71d4f4e35006b35f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
