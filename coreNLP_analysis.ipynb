{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Data Analysis Project\n",
    "**Team**: ToeStewBrr - Alexander Sternfeld, Marguerite Thery, Antoine Bonnet, Hugo Bordereaux\n",
    "\n",
    "**Dataset**: CMU Movie Summary Corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreNLP Analysis\n",
    "\n",
    "[**CoreNLP**](https://nlp.stanford.edu/software/) is an incredible natural language processing toolkit created at Stanford University. CoreNLP is applied through a **pipeline** of sequential analysis steps called annotators. The full list of available annotators is available [here](https://stanfordnlp.github.io/CoreNLP/annotators.html). \n",
    "\n",
    "As described by its creators: \n",
    "\n",
    "*\"CoreNLP is your one stop shop for natural language processing in Java! CoreNLP enables users to derive linguistic annotations for text, including token and sentence boundaries, parts of speech, named entities, numeric and time values, dependency and constituency parses, coreference, sentiment, quote attributions, and relations. CoreNLP currently supports 8 languages: Arabic, Chinese, English, French, German, Hungarian, Italian, and Spanish.\"* \n",
    "\n",
    "You can create your own pipeline to extract the desired information. You can try it out for yourself in this [online shell](https://corenlp.run).\n",
    "\n",
    "### Loading data\n",
    "We first load data files and download the pre-processed dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "from load_data import *\n",
    "from coreNLP_analysis import *\n",
    "\n",
    "download_data(coreNLP=False)\n",
    "plot_df = load_plot_df()\n",
    "movie_df = load_movie_df()\n",
    "char_df = load_char_df()\n",
    "names_df = load_names_df()\n",
    "cluster_df = load_cluster_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exploring pre-processed CoreNLP data\n",
    "\n",
    "The authors of the Movie CMU dataset used CoreNLP to parse each plot summary to extract various linguistic insights. In this section, we explore how much information we can gather from these pre-processed files. \n",
    "\n",
    "We will use *Harry Potter*'s character throughout this section.\n",
    "\n",
    "#### 1.1. Character data\n",
    "\n",
    "For any character, we first extract related information from the provided name clusters and character metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with character Harry Potter :\n",
      "\tMovie IDs: [858575, 667372, 670407, 31941988, 9834441, 667368, 667371, 667361, 667361]\n",
      "\tCharacter IDs: ['/m/0jz6jt', '/m/02tbbh6', '/m/0jz6mq', '/m/0jz6hs', '/m/02tbf6n', '/m/0jz6b0', '/m/0jz6dz', '/m/09lybcb']\n",
      "\tTrope: None\n",
      "Selecting as example: \n",
      "\tMovie ID: 31941988 \n",
      "\tMovie title: Harry Potter and the Deathly Hallows – Part 2\n"
     ]
    }
   ],
   "source": [
    "# Given character, extract all pre-processed dataframe data\n",
    "char_name = 'Harry Potter'\n",
    "movie_ids = list(char_df[char_df['Character name'] == char_name]['Wikipedia ID'])\n",
    "char_ids = names_df.loc[char_name].values[0]\n",
    "trope = cluster_df.loc[cluster_df['Character name'] == char_name]\n",
    "\n",
    "# If no trope is found, set it to None\n",
    "if trope.empty:\n",
    "    trope = None\n",
    "\n",
    "print('Movies with character', char_name, ':')\n",
    "print('\\tMovie IDs:', movie_ids)\n",
    "print('\\tCharacter IDs:', char_ids)\n",
    "print('\\tTrope:', trope)\n",
    "\n",
    "movie_id = movie_ids[3] \n",
    "movie_name = movie_df.loc[movie_df['Wikipedia ID'] == movie_id]['Name'].iloc[0]\n",
    "print('Selecting as example: \\n\\tMovie ID:', movie_id, '\\n\\tMovie title:', movie_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Extracting sentences\n",
    "\n",
    "We now extract information from the CoreNLP plot summary analysis. The authors of the dataset stored the analysis output of each movie into a `.xml` file. Each file has a tree structure detailing each word of each sentence as well as the parsed sentence in tree form. \n",
    "\n",
    "We now extract all parsed sentences from the `.xml` files. \n",
    "\n",
    "A **parsed sentence** is a syntactic analysis tree, where each word is a leaf tagged by its lexical function (e.g. *VBZ* for verbs or *DT* for determinants). Semantic interactions between different words are also indicated within the structure of the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT (S (PP (IN In) (NP (NP (NNP Bellatrix) (POS 's)) (NN vault))) (, ,) (NP (NNP Harry)) (VP (VBZ discovers) (SBAR (S (NP (DT the) (NNP Horcrux)) (VP (VBZ is) (NP (NP (NNP Helga) (NNP Hufflepuff) (POS 's)) (NN cup)))))) (. .))) \n",
      "                                                ROOT                                                 \n",
      "                                                 |                                                    \n",
      "                                                 S                                                   \n",
      "                _________________________________|_________________________________________________   \n",
      "               |             |    |                               VP                               | \n",
      "               |             |    |        _______________________|____                            |  \n",
      "               |             |    |       |                           SBAR                         | \n",
      "               |             |    |       |                            |                           |  \n",
      "               |             |    |       |                            S                           | \n",
      "               |             |    |       |            ________________|_______                    |  \n",
      "               PP            |    |       |           |                        VP                  | \n",
      "  _____________|___          |    |       |           |            ____________|_______            |  \n",
      " |                 NP        |    |       |           |           |                    NP          | \n",
      " |              ___|____     |    |       |           |           |             _______|_______    |  \n",
      " |             NP       |    |    NP      |           NP          |            NP              |   | \n",
      " |       ______|___     |    |    |       |       ____|_____      |     _______|___________    |   |  \n",
      " IN    NNP        POS   NN   ,   NNP     VBZ     DT        NNP   VBZ  NNP     NNP         POS  NN  . \n",
      " |      |          |    |    |    |       |      |          |     |    |       |           |   |   |  \n",
      " In Bellatrix      's vault  ,  Harry discovers the      Horcrux  is Helga Hufflepuff      's cup  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the tree of xml file and all parsed sentences\n",
    "tree = get_tree(movie_id)\n",
    "sentences = get_parsed_sentences(tree)\n",
    "\n",
    "# Picking the fifth sentence as example\n",
    "parsed_str = sentences[5]\n",
    "print(parsed_str)\n",
    "print_tree(parsed_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Extracting characters\n",
    "\n",
    "We also want to extract all character names directly from the xml file. Note that we aggregate consecutive words tagged as NNP (noun, proper, singular) as the same character name (this assumes that plot summaries never contain two distinct names side by side without delimiting punctuation). This is a reasonable assumption since list of names are almost always separated by commas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Voldemort', 'Albus Dumbledore', 'Severus Snape', 'Dobby', 'Harry Potter', 'Ron', 'Hermione', 'Griphook', 'Harry', 'Ollivander', 'Ollivander', 'Draco Malfoy', 'Malfoy', 'Harry', 'Harry', 'Helga Hufflepuff', 'Griphook', 'Harry', 'Voldemort', 'Griphook']\n"
     ]
    }
   ],
   "source": [
    "characters = get_characters(tree)\n",
    "print(characters[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some characters are sometimes mentioned by their full name, and sometimes by a partial name (e.g. Harry Potter is most often mentioned as simply Harry). To get a more precise idea of how many times each character is mentioned, we wish to denote each character by their full name, i.e. the longest version of their name that appears in the plot summary. \n",
    "\n",
    "*NOTE*: The dataset has the character metadata of only a third of the movies, so we need to extract full names from the plot summary itself and not the provided dataframes. \n",
    "\n",
    "To optimize full name lookup, for each plot summary we construct a dictionary which stores as key every partial name mentioned, and as corresponding values the full name of each character.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: the full name of \"Albus\" is \"Albus Dumbledore\".\n",
      "Full name dictionary: {'Voldemort': 'Voldemort', 'Albus Dumbledore': 'Albus Dumbledore', 'Severus Snape': 'Severus Snape', 'Dobby': 'Dobby', 'Harry Potter': 'Harry Potter', 'Ron': 'Ron', 'Hermione': 'Hermione Weasley', 'Griphook': 'Griphook', 'Harry': 'Harry Potter', 'Ollivander': 'Ollivander', 'Draco Malfoy': 'Draco Malfoy', 'Malfoy': 'Draco Malfoy', 'Helga Hufflepuff': 'Helga Hufflepuff', 'Rowena Ravenclaw': 'Rowena Ravenclaw', 'Hogsmeade': 'Hogsmeade', 'Aberforth Dumbledore': 'Aberforth Dumbledore', 'Ariana': 'Ariana', 'Neville Longbottom': 'Neville Longbottom', 'Snape': 'Severus Snape', 'Minerva McGonagall': 'Minerva McGonagall', 'Luna Lovegood': 'Luna Lovegood', 'Helena Ravenclaw': 'Helena Ravenclaw', 'Gregory Goyle': 'Gregory Goyle', 'Blaise Zabini': 'Blaise Zabini', 'Nagini': 'Nagini', 'Fred': 'Fred', 'Lily': 'Lily', 'James': 'James', 'Dumbledore': 'Albus Dumbledore', 'Neville': 'Neville Longbottom', 'Molly Weasley': 'Molly Weasley', 'Ginny Potter': 'Ginny Potter', 'Hermione Weasley': 'Hermione Weasley'}\n"
     ]
    }
   ],
   "source": [
    "char_name = 'Albus'\n",
    "full_name = get_full_name(char_name, characters)\n",
    "print('Example: the full name of \"{}\" is \"{}\".'.format(char_name,full_name))\n",
    "print('Full name dictionary:', full_name_dict(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract the most mentioned characters in any plot summary, in descending order of frequency. We can then see that Harry Potter is indeed the main character of the movie, as he is mentioned 26 times, more than any other character in the summary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Harry Potter', 26), ('Voldemort', 21), ('Severus Snape', 11), ('Ron', 6), ('Hermione Weasley', 6), ('Albus Dumbledore', 5), ('Griphook', 3), ('Draco Malfoy', 3), ('Neville Longbottom', 3), ('Nagini', 3), ('Ollivander', 2), ('Lily', 2), ('Dobby', 1), ('Helga Hufflepuff', 1), ('Rowena Ravenclaw', 1), ('Hogsmeade', 1), ('Aberforth Dumbledore', 1), ('Ariana', 1), ('Minerva McGonagall', 1), ('Luna Lovegood', 1), ('Helena Ravenclaw', 1), ('Gregory Goyle', 1), ('Blaise Zabini', 1), ('Fred', 1), ('James', 1), ('Molly Weasley', 1), ('Ginny Potter', 1)]\n"
     ]
    }
   ],
   "source": [
    "char_mentions = most_mentioned(movie_id)\n",
    "print(char_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 1.4. Extracting interactions\n",
    "\n",
    "We are also interested in character interactions. We can use the number of common mentions of two characters in the same sentence as a proxy for the number of interactions. For any movie, we find the number of common mentions (i.e. interactions) for each pair of characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('Hermione Weasley', 'Ron'), 4), (('Harry Potter', 'Voldemort'), 4), (('Albus Dumbledore', 'Voldemort'), 3), (('Albus Dumbledore', 'Severus Snape'), 2), (('Harry Potter', 'Hermione Weasley'), 2), (('Harry Potter', 'Ron'), 2), (('Nagini', 'Voldemort'), 2), (('Harry Potter', 'Lily'), 2), (('Albus Dumbledore', 'Harry Potter'), 2), (('Severus Snape', 'Voldemort'), 1)]\n"
     ]
    }
   ],
   "source": [
    "char_pairs = character_pairs(movie_id, plot_df)\n",
    "print(char_pairs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main interaction in the movie: ('Hermione Weasley', 'Ron')\n"
     ]
    }
   ],
   "source": [
    "main_interaction = character_pairs(movie_id, plot_df)[0][0]\n",
    "print('Main interaction in the movie:', main_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Extracting characters and interactions of all movies\n",
    "\n",
    "We will now use the above code to obtain the main character and main interaction for every plot summary. \n",
    "\n",
    "*NOTE*: This code takes a while to run, so you can load the analysis from a pre-processed file instead.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Main character</th>\n",
       "      <th>Number of mentions</th>\n",
       "      <th>Main interaction</th>\n",
       "      <th>Number of interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>Shlykov</td>\n",
       "      <td>1.0</td>\n",
       "      <td>('Lyosha', 'Shlykov')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "      <td>Katniss</td>\n",
       "      <td>18.0</td>\n",
       "      <td>('Katniss', 'Peeta Mellark')</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "      <td>Maranchery Karunakara Menon</td>\n",
       "      <td>9.0</td>\n",
       "      <td>('Manapally Madhavan Nambiar', 'judge Menon')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "      <td>Charley</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "      <td>Lindy</td>\n",
       "      <td>7.0</td>\n",
       "      <td>('Azaria', 'Lindy')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42298</th>\n",
       "      <td>34808485</td>\n",
       "      <td>The story is about Reema , a young Muslim scho...</td>\n",
       "      <td>Reema</td>\n",
       "      <td>1.0</td>\n",
       "      <td>('Muslim', 'Reema')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42299</th>\n",
       "      <td>1096473</td>\n",
       "      <td>In 1928 Hollywood, director Leo Andreyev  look...</td>\n",
       "      <td>Leo Andreyev</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42300</th>\n",
       "      <td>35102018</td>\n",
       "      <td>American Luthier focuses on Randy Parsons’ tra...</td>\n",
       "      <td>Randy Parsons</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42301</th>\n",
       "      <td>8628195</td>\n",
       "      <td>Abdur Rehman Khan , a middle-aged dry fruit se...</td>\n",
       "      <td>Abdur Rehman Khan</td>\n",
       "      <td>9.0</td>\n",
       "      <td>('Abdur Rehman Khan', 'Amina')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42302</th>\n",
       "      <td>6040782</td>\n",
       "      <td>1940 - Operation Dynamo has just taken place. ...</td>\n",
       "      <td>George Mainwaring</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42303 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia ID                                            Summary  \\\n",
       "0          23890098  Shlykov, a hard-working taxi driver and Lyosha...   \n",
       "1          31186339  The nation of Panem consists of a wealthy Capi...   \n",
       "2          20663735  Poovalli Induchoodan  is sentenced for six yea...   \n",
       "3           2231378  The Lemon Drop Kid , a New York City swindler,...   \n",
       "4            595909  Seventh-day Adventist Church pastor Michael Ch...   \n",
       "...             ...                                                ...   \n",
       "42298      34808485  The story is about Reema , a young Muslim scho...   \n",
       "42299       1096473  In 1928 Hollywood, director Leo Andreyev  look...   \n",
       "42300      35102018  American Luthier focuses on Randy Parsons’ tra...   \n",
       "42301       8628195  Abdur Rehman Khan , a middle-aged dry fruit se...   \n",
       "42302       6040782  1940 - Operation Dynamo has just taken place. ...   \n",
       "\n",
       "                    Main character  Number of mentions  \\\n",
       "0                          Shlykov                 1.0   \n",
       "1                          Katniss                18.0   \n",
       "2      Maranchery Karunakara Menon                 9.0   \n",
       "3                          Charley                18.0   \n",
       "4                            Lindy                 7.0   \n",
       "...                            ...                 ...   \n",
       "42298                        Reema                 1.0   \n",
       "42299                 Leo Andreyev                 7.0   \n",
       "42300                Randy Parsons                 4.0   \n",
       "42301            Abdur Rehman Khan                 9.0   \n",
       "42302            George Mainwaring                 9.0   \n",
       "\n",
       "                                    Main interaction  Number of interactions  \n",
       "0                              ('Lyosha', 'Shlykov')                     1.0  \n",
       "1                       ('Katniss', 'Peeta Mellark')                     2.0  \n",
       "2      ('Manapally Madhavan Nambiar', 'judge Menon')                     1.0  \n",
       "3                                                NaN                     NaN  \n",
       "4                                ('Azaria', 'Lindy')                     1.0  \n",
       "...                                              ...                     ...  \n",
       "42298                            ('Muslim', 'Reema')                     1.0  \n",
       "42299                                            NaN                     NaN  \n",
       "42300                                            NaN                     NaN  \n",
       "42301                 ('Abdur Rehman Khan', 'Amina')                     1.0  \n",
       "42302                                            NaN                     NaN  \n",
       "\n",
       "[42303 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: If we've already run this code, we can load the dataframe from a file\n",
    "pairs_df = pd.read_csv('Data/MovieSummaries/plot_characters.csv', sep='\\t', index_col=0)\n",
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otherwise: get main character and number of mentions for each movie and store it into a file (takes a while to run) \n",
    "pairs_df = plot_df.copy(deep=True)\n",
    "pairs_df['Main character'] = pairs_df['Wikipedia ID'].apply(most_mentioned)\n",
    "pairs_df['Number of mentions'] = pairs_df['Main character'].apply(lambda x: np.nan if x is None else x[0][1])\n",
    "pairs_df['Main character'] = pairs_df['Main character'].apply(lambda x: np.nan if x is None else x[0][0])\n",
    "\n",
    "# Get main pairs of characters for each movie and number of interactions \n",
    "pairs_df['Main interaction'] = pairs_df['Wikipedia ID'].apply(lambda x: character_pairs(x, plot_df))\n",
    "pairs_df['Number of interactions'] = pairs_df['Main interaction'].apply(lambda x: np.nan if x is None else x[0][1])\n",
    "pairs_df['Main interaction'] = pairs_df['Main interaction'].apply(lambda x: np.nan if x is None else x[0][0])\n",
    "\n",
    "# Store data into csv file\n",
    "pairs_df.to_csv('Data/MovieSummaries/plot_characters.csv', sep='\\t')^\n",
    "pairs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the coreNLP files provided with the datasets are useful to extract the characters mentioned. \n",
    "\n",
    " However, our goal is to extract love relationships as well as the persona of characters in love. Using common mentions as a proxy for love relationships is a vulgar approximation and so we must run our own NLP analysis on the plot summaries to extract useful information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Custom CoreNLP Analysis\n",
    "\n",
    "We now use a **custom CoreNLP pipeline** to analyze the plot summaries. Due to the weakness of our available computing power, we will only analyze romantic comedy movies for now. \n",
    "\n",
    "Our custom pipeline consists of the following annotators: \n",
    "\n",
    "1. [Tokenization (tokenize)](https://stanfordnlp.github.io/CoreNLP/tokenize.html): Turns the whole text into tokens. \n",
    "\n",
    "2. [Parts Of Speech (POS)](https://stanfordnlp.github.io/CoreNLP/pos.html): Tags each token with part of speech labels (e.g. determinants, verbs and nouns). \n",
    "\n",
    "3. [Lemmatization (lemma)](https://stanfordnlp.github.io/CoreNLP/lemma.html): Reduces each word to its lemma (e.g. *was* becomes *be*). \n",
    "\n",
    "4. [Named Entity Recognition (NER)](https://stanfordnlp.github.io/CoreNLP/ner.html): Identifies named entities from the text, including characters, locations and organizations. \n",
    "\n",
    "5. [Constituency parsing (parse)](https://stanfordnlp.github.io/CoreNLP/parse.html): Performs a syntactic analysis of each sentence in the form of a tree. \n",
    "\n",
    "6. [Coreference resolution (coref)](https://stanfordnlp.github.io/CoreNLP/coref.html): Aggregates mentions of the same entities in a text (e.g. when 'Harry' and 'he' refer to the same person). \n",
    "\n",
    "7. [Dependency parsing (depparse)](https://stanfordnlp.github.io/CoreNLP/depparse.html): Syntactic dependency parser. \n",
    "\n",
    "8. [Natural Logic (natlog)](https://stanfordnlp.github.io/CoreNLP/natlog.html): Identifies quantifier scope and token polarity. Required as preliminary for OpenIE. \n",
    "\n",
    "9. [Open Information Extraction (OpenIE)](https://stanfordnlp.github.io/CoreNLP/openie.html): Identifies relation between words as triples *(subject, relation, object of relation)*. We use this to extract relationships between characters, as well as character traits. \n",
    "\n",
    "10. [Knowledge Base Population (KBP)](https://stanfordnlp.github.io/CoreNLP/kbp.html): Identifies meaningful relation triples. \n",
    "\n",
    "\n",
    "#### 2.1. Running our pipeline\n",
    "\n",
    "We now run our own CoreNLP analysis on the plot summaries. This allows us to extract love relationships from the plot summaries much more accurately. \n",
    "\n",
    "**Goal**: Run our custom CoreNLP pipeline. \n",
    "\n",
    "**Recommendation**: Be careful about memory storage (takes a lot of memory to run!)\n",
    "\n",
    "**Prerequisite**: [java](https://www.java.com). \n",
    "\n",
    "**Installation steps**:\n",
    "1. Download the CoreNLP toolkit [here](https://stanfordnlp.github.io/CoreNLP/download.html).\n",
    "\n",
    "2. Change directory (`cd`) into the downloaded `stanford-corenlp` directory. \n",
    "\n",
    "3. Data preparation: Extract plot summaries for romantic comedies into `.txt` files. Create a filelist containing the name of all the files which need to be processed using the following command in your terminal: \n",
    "\n",
    "<center>find RomancePlots/*.txt > filelist.txt</center>\n",
    "        \n",
    "4. Run the custom CoreNLP pipeline via your terminal using the following command:\n",
    "\n",
    "<center>java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,pos,lemma,ner,parse,coref,depparse,natlog,openie,kbp -coref.md.type RULE -filelist filelist.txt -outputDirectory RomancePlotsOutputs/ -outputFormat xml</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the romantic comedy plot summaries we passed through our pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6631279</td>\n",
       "      <td>Adam, a San Francisco-based artist who works a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21926710</td>\n",
       "      <td>Jimmy ([[Hiroshi Watanabe  loves dinosaurs and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26067101</td>\n",
       "      <td>Perry is an English chemist working for a pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12053509</td>\n",
       "      <td>Randy Bodek  is a rebellious college slacker, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7028314</td>\n",
       "      <td>Sir Philip Ashlow , his neglected wife, Lady A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>1001692</td>\n",
       "      <td>Leslie Steele , a guest at a costume party is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>25655938</td>\n",
       "      <td>Kate Tosconi is a journalist in her early 20s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>11823946</td>\n",
       "      <td>Viola  and Sebastian  are young twins and ente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>30553937</td>\n",
       "      <td>A daytime soap opera star has to deal with his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>54540</td>\n",
       "      <td>Akeem Joffer , the prince and heir to the thro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2075 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Wikipedia ID                                            Summary\n",
       "0          6631279  Adam, a San Francisco-based artist who works a...\n",
       "1         21926710  Jimmy ([[Hiroshi Watanabe  loves dinosaurs and...\n",
       "2         26067101  Perry is an English chemist working for a pain...\n",
       "3         12053509  Randy Bodek  is a rebellious college slacker, ...\n",
       "4          7028314  Sir Philip Ashlow , his neglected wife, Lady A...\n",
       "...            ...                                                ...\n",
       "2675       1001692  Leslie Steele , a guest at a costume party is ...\n",
       "2676      25655938  Kate Tosconi is a journalist in her early 20s ...\n",
       "2677      11823946  Viola  and Sebastian  are young twins and ente...\n",
       "2678      30553937  A daytime soap opera star has to deal with his...\n",
       "2679         54540  Akeem Joffer , the prince and heir to the thro...\n",
       "\n",
       "[2075 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a dataframe with romantic movies and their corresponding plots\n",
    "romance_genres = ['Romantic comedy'] \n",
    "# For later use: romance_genres = ['Romantic comedy', 'Romance Film', 'Romantic drama', 'Romantic fantasy', 'Romantic thriller']\n",
    "rom_com_plots = get_plots(romance_genres, movie_df, plot_df)\n",
    "rom_com_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all romantic comedies plots into separate txt files to be able to run them through the new coreNLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in rom_com_plots.iterrows():\n",
    "#     with open(\"Data/MovieSummaries/RomancePlots/{}.txt\".format(row['Wikipedia ID']), 'w') as f:\n",
    "#         if type(row['Summary']) == str:\n",
    "#             f.write(row['Summary'])\n",
    "#             f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip \n",
    "with ZipFile('Romance_Data/RomancePlotsOutputs.zip', 'r') as zipObj:\n",
    "   # Extract all the romance plots xml files\n",
    "   zipObj.extractall('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each xml file representing a romantic movie, we extract the kbp title relationship. \n",
    "TODO: Rerun corenlp on the files 43849.txt.xml and 1282593.txt.xml which cannot be parsed as trees. Update the zip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be moved to python file once done\n",
    "# Create a list of tuples containing (movie_id, subject, object) for each kbp triples with title relationship\n",
    "def get_relation_df(DIR, relation_type): \n",
    "    title = []\n",
    "    for filename in os.listdir(DIR):\n",
    "        # Manually deleted files: 43849.txt.xml and 1282593.txt.xml because could not be parsed\n",
    "        if filename != \".DS_Store\" and filename != \"43849.txt.xml\" and filename != \"1282593.txt.xml\":\n",
    "            movie_id = filename[:-8]\n",
    "            title.append(get_relation(movie_id, relation_type))\n",
    "    title_df = pd.DataFrame([item for sublist in title for item in sublist], columns=['Wikipedia ID', 'Subject', 'Title'])\n",
    "    title_df = title_df.groupby(['Wikipedia ID','Subject'])['Title'].apply(', '.join).reset_index()  \n",
    "    return title_df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of relevant relationships to chose from: \n",
    "- per_age\n",
    "- per_alternate_names\n",
    "- per_cause_of_death\n",
    "- per_children\n",
    "- per_cities_of_residence\n",
    "- per_city_of_birth\n",
    "- per_city_of_death\n",
    "- per_countries_of_residence\n",
    "- per_country_of_birth\n",
    "- per_country_of_death\n",
    "- per_date_of_birth\n",
    "- per_date_of_death\n",
    "- per_employee_of\n",
    "- per_member_of\n",
    "- per_origin\n",
    "- per_other_family\n",
    "- per_parents\n",
    "- per_religion\n",
    "- per_schools_attended\n",
    "- per_siblings\n",
    "- per_spouse\n",
    "- per_stateorprovince_of_birth\n",
    "- per_stateorprovince_of_death\n",
    "- per_stateorprovinces_of_residence\n",
    "- per_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002717</td>\n",
       "      <td>Delia Darrow</td>\n",
       "      <td>assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002717</td>\n",
       "      <td>Fergie</td>\n",
       "      <td>Inspector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002717</td>\n",
       "      <td>Gerda Caswell</td>\n",
       "      <td>assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1002717</td>\n",
       "      <td>Gloria Mundy</td>\n",
       "      <td>librarian, manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1002717</td>\n",
       "      <td>Rachel Roberts</td>\n",
       "      <td>assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>4339865</td>\n",
       "      <td>Max de Mirecourt</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>4339865</td>\n",
       "      <td>Tam Tam</td>\n",
       "      <td>Princess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>4340003</td>\n",
       "      <td>Danny Miller</td>\n",
       "      <td>producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>4340003</td>\n",
       "      <td>Max Corkle</td>\n",
       "      <td>messenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>436955</td>\n",
       "      <td>Ruthie</td>\n",
       "      <td>manager</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1909 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Wikipedia ID           Subject               Title\n",
       "0         1002717      Delia Darrow           assistant\n",
       "1         1002717            Fergie           Inspector\n",
       "2         1002717     Gerda Caswell           assistant\n",
       "3         1002717      Gloria Mundy  librarian, manager\n",
       "4         1002717    Rachel Roberts           assistant\n",
       "...           ...               ...                 ...\n",
       "1904      4339865  Max de Mirecourt              writer\n",
       "1905      4339865           Tam Tam            Princess\n",
       "1906      4340003      Danny Miller            producer\n",
       "1907      4340003        Max Corkle           messenger\n",
       "1908       436955            Ruthie             manager\n",
       "\n",
       "[1909 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_df = get_relation_df(DIR = 'RomancePlotsOutputs/', relation_type = 'per:title')\n",
    "title_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RomancePlotsOutputs has 1491 readable files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001692</td>\n",
       "      <td>Steele</td>\n",
       "      <td>Lady Claire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006385</td>\n",
       "      <td>Lindsay</td>\n",
       "      <td>Rose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10095235</td>\n",
       "      <td>Diogo Álvares</td>\n",
       "      <td>Diogo Álvares, Paraguaçu, Diogo Álvares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10095235</td>\n",
       "      <td>Paraguaçu</td>\n",
       "      <td>Diogo Álvares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10190365</td>\n",
       "      <td>Paro</td>\n",
       "      <td>Shambunath Mehta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>431333</td>\n",
       "      <td>Toula</td>\n",
       "      <td>Toula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>4339865</td>\n",
       "      <td>Lucie</td>\n",
       "      <td>Max de Mirecourt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>4339865</td>\n",
       "      <td>Max de Mirecourt</td>\n",
       "      <td>Lucie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>4343386</td>\n",
       "      <td>Kathy</td>\n",
       "      <td>Peter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>4343386</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Kathy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>523 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Wikipedia ID           Subject                                    Title\n",
       "0        1001692            Steele                              Lady Claire\n",
       "1        1006385           Lindsay                                     Rose\n",
       "2       10095235     Diogo Álvares  Diogo Álvares, Paraguaçu, Diogo Álvares\n",
       "3       10095235         Paraguaçu                            Diogo Álvares\n",
       "4       10190365              Paro                         Shambunath Mehta\n",
       "..           ...               ...                                      ...\n",
       "518       431333             Toula                                    Toula\n",
       "519      4339865             Lucie                         Max de Mirecourt\n",
       "520      4339865  Max de Mirecourt                                    Lucie\n",
       "521      4343386             Kathy                                    Peter\n",
       "522      4343386             Peter                                    Kathy\n",
       "\n",
       "[523 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "love_df = get_relation_df(DIR = 'RomancePlotsOutputs/', relation_type = 'per:spouse')\n",
    "love_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_df = get_relation_df(DIR = 'RomancePlotsOutputs/', relation_type = 'per:cause_of_death')\n",
    "death_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
