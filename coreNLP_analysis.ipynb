{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Data Analysis Project\n",
    "**Team**: ToeStewBrr - Alexander Sternfeld, Marguerite Thery, Antoine Bonnet, Hugo Bordereaux\n",
    "\n",
    "**Dataset**: CMU Movie Summary Corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CoreNLP Analysis\n",
    "\n",
    "We first load data files and download the pre-processed dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "from coreNLP_analysis import *\n",
    "\n",
    "download_data()\n",
    "plot_df = load_plot_df()\n",
    "movie_df = load_movie_df()\n",
    "char_df = load_char_df()\n",
    "names_df = load_names_df()\n",
    "cluster_df = load_cluster_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Extracting characters\n",
    "\n",
    "For any character, we want to extract related information (from name clusters, character metadata) as well as actions, characteristics and relations (from CoreNLP). We first extract information from the pre-processed dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Harry Potter's character as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_name = 'Harry Potter'\n",
    "movie_ids = list(char_df[char_df['Character name'] == 'Harry Potter']['Wikipedia ID'])\n",
    "char_ids = names_df.loc[char_name].values[0]\n",
    "trope = cluster_df.loc[cluster_df['Character name'] == char_name]\n",
    "# if trop is empty, set trope to None\n",
    "if trope.empty:\n",
    "    trope = None\n",
    "\n",
    "print('Movies with character', char_name, ':')\n",
    "print('\\tMovie IDs:', movie_ids)\n",
    "print('\\tCharacter IDs:', char_ids)\n",
    "print('\\tTrope:', trope)\n",
    "\n",
    "movie_id = movie_ids[3] \n",
    "print('Selecting movie ID as example:', movie_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extract information from the CoreNLP plot summary analysis. Each xml file has a tree structure detailing each word of each sentence as well as the parsed sentence in tree form. We extract all parsed sentences from the xml file, each of which we can view as a tree structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = get_tree(movie_id)\n",
    "parsed_str = get_parsed_sentences(tree)[5]\n",
    "print(parsed_str)\n",
    "print_tree(parsed_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to extract all character names from the xml file. Note that we aggregate consecutive words tagged as NNP (noun, proper, singular) as the same character name (this assumes that plot summaries never contain two distinct names side by side without delimiting punctuation). This is a reasonable assumption since list of names are almost always separated by commas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = get_characters(tree)\n",
    "characters[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some characters are sometimes mentioned by their full name, and sometimes by a partial name (e.g. Harry Potter is most often mentioned as simply Harry). To get a more precise idea of how many times each character is mentioned, we wish to denote each character by their full name, i.e. the longest version of their name that appears in the plot summary. \n",
    "\n",
    "To optimize full name lookup, for each plot summary we construct a dictionary which stores as key every partial name mentioned, and as corresponding values the full name of each character.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_name = 'Albus'\n",
    "full_name = get_full_name(char_name, characters)\n",
    "print('Example: the full name of \"{}\" is \"{}\".'.format(char_name,full_name))\n",
    "print('Full name dictionary:', full_name_dict(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the list of character full names, we can now construct a dictionary with keys being the characters' full name and values being the number of times any version of their name is mentioned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_characters(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract the most mentioned characters in any plot summary, in descending order of frequency. We can then see that Harry Potter is indeed the main character of the movie, as he is mentioned 26 times, more than any other character in the summary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_mentioned(movie_id)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 4.2. Extracting relationships\n",
    "\n",
    " We cannot extract character interactions directly from the CoreNLP output (or can we?). Instead, we use the number of common mentions of two characters in the same sentence as a proxy for the number of interactions. For any movie, we find the number of common mentions (i.e. interactions) for each pair of characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_pairs(movie_id, plot_df)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_interaction = character_pairs(movie_id, plot_df)[0][0]\n",
    "main_interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Extracting main character and interactions\n",
    "\n",
    "We will now use the above code to obtain the main character and most important pair of characters for every plot summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df = plot_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Get main character and number of mentions for each movie\n",
    "pairs_df['Main character'] = pairs_df['Wikipedia ID'].apply(most_mentioned)\n",
    "pairs_df['Number of mentions'] = pairs_df['Main character'].apply(lambda x: np.nan if x is None else x[0][1])\n",
    "pairs_df['Main character'] = pairs_df['Main character'].apply(lambda x: np.nan if x is None else x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get main pairs of characters for each movie and number of interactions \n",
    "pairs_df['Main interaction'] = pairs_df['Wikipedia ID'].apply(lambda x: character_pairs(x, plot_df))\n",
    "pairs_df['Number of interactions'] = pairs_df['Main interaction'].apply(lambda x: np.nan if x is None else x[0][1])\n",
    "pairs_df['Main interaction'] = pairs_df['Main interaction'].apply(lambda x: np.nan if x is None else x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df.to_csv('Data/MovieSummaries/plot_characters.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge pairs dataset with characters \n",
    "char_df['Wikipedia ID'] = char_df['Wikipedia ID'].astype(str)\n",
    "pairs_df['Wikipedia ID'] = pairs_df['Wikipedia ID'].astype(str)\n",
    "pairs_char = pairs_df.merge(char_df, on=\"Wikipedia ID\")\n",
    "\n",
    "# Filter out the nan values\n",
    "pairs_char = pairs_char[~pairs_char['Character name'].isna()]\n",
    "\n",
    "# Create columns which indicates if char1 and char2 are in character name \n",
    "pairs_char['char1_is_in_name'] = pairs_char.apply(lambda x: 1 if x['char1'] in x['Character name'] else 0, axis=1)\n",
    "pairs_char['char2_is_in_name'] = pairs_char.apply(lambda x: 1 if x['char2'] in x['Character name'] else 0, axis=1)\n",
    "pairs_char[pairs_char['char1_is_in_name'] == 1 & pairs_char['char2_is_in_name'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. CoreNLP Analysis\n",
    "\n",
    "- Prerequisite: java. \n",
    "- Be careful about the memory storage\n",
    "- To use the powerful CoreNLP model, first [download it](https://stanfordnlp.github.io/CoreNLP/download.html), then cd into the downloaded `stanford-corenlp` directory. \n",
    "- Run the coreNLP pipeline with openIE (https://stanfordnlp.github.io/CoreNLP/openie.html) and kbp (https://stanfordnlp.github.io/CoreNLP/kbp.html) annotators. \n",
    "- We extract plot summaries for romantic comedies (next step: all romantic movies) into txt files. \n",
    "- Create a filelist to pass as argument to the command containing the name of all the files which need to be process: \n",
    "    - find RomancePlots/*.txt > filelist.txt\n",
    "- Run the following command via the command line: \n",
    "    - java -mx3g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,pos,lemma,ner,parse,coref,depparse,natlog,openie,kbp -coref.md.type RULE -filelist filelist.txt -outputDirectory RomancePlotsOutputs/ -outputFormat xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the plots of romantic movies\n",
    "romance_genres = ['Romantic comedy'] #, 'Romance Film', 'Romantic drama', 'Romantic fantasy', 'Romantic thriller']\n",
    "is_romantic = lambda i: lambda x: any(y in romance_genres[i] for y in x) if type(x) == list else False\n",
    "romance_com = movie_df[movie_df['Genres'].apply(is_romantic(slice(0, 5)))]\n",
    "rom_com_plots = romance_com.merge(plot_df, on='Wikipedia ID', how='left')[['Wikipedia ID', 'Summary']]\n",
    "rom_com_plots = rom_com_plots[~rom_com_plots['Summary'].isna()]\n",
    "rom_com_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all romantic comedies plots into separate txt files to be able to run them through the new coreNLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in rom_com_plots.iterrows():\n",
    "    with open(\"Data/MovieSummaries/RomancePlots/{}.txt\".format(row['Wikipedia ID']), 'w') as f:\n",
    "        if type(row['Summary']) == str:\n",
    "            f.write(row['Summary'])\n",
    "            f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8df04c4e7c0125b8c70fc020e0a0390d1dc6940b37b05a71d4f4e35006b35f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
